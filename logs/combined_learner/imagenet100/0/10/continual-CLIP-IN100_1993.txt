2026-01-16 00:59:14,622 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 00:59:14,622 [trainer.py] => dataset: imagenet100
2026-01-16 00:59:14,622 [trainer.py] => shuffle: True
2026-01-16 00:59:14,623 [trainer.py] => init_cls: 10
2026-01-16 00:59:14,623 [trainer.py] => increment: 10
2026-01-16 00:59:14,623 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 00:59:14,623 [trainer.py] => sim: 1
2026-01-16 00:59:14,626 [trainer.py] => epochs: 31
2026-01-16 00:59:14,629 [trainer.py] => lr: 0.01
2026-01-16 00:59:14,635 [trainer.py] => FB_epoch: 51
2026-01-16 00:59:14,635 [trainer.py] => FB_epoch_inc: 31
2026-01-16 00:59:14,636 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 00:59:14,636 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 00:59:14,636 [trainer.py] => pool: 10
2026-01-16 00:59:14,636 [trainer.py] => sg_num: 1
2026-01-16 00:59:14,636 [trainer.py] => gamma: 0.1
2026-01-16 00:59:14,637 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 00:59:14,637 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 00:59:14,637 [trainer.py] => model_name: combined_learner
2026-01-16 00:59:14,637 [trainer.py] => model_size: ViT-B/16
2026-01-16 00:59:14,637 [trainer.py] => convnet_type: none
2026-01-16 00:59:14,637 [trainer.py] => seed: 1993
2026-01-16 00:59:14,637 [trainer.py] => batch_size: 64
2026-01-16 00:59:14,638 [trainer.py] => num_workers: 8
2026-01-16 00:59:14,638 [trainer.py] => model_type: clip
2026-01-16 00:59:14,638 [trainer.py] => division_power: 5
2026-01-16 00:59:14,642 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 00:59:14,649 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 00:59:14,650 [trainer.py] => regularizer: mahalanobis
2026-01-16 00:59:14,650 [trainer.py] => print_freq: 10
2026-01-16 00:59:14,650 [trainer.py] => memory_size: 0
2026-01-16 00:59:14,650 [trainer.py] => k: 10
2026-01-16 00:59:14,651 [trainer.py] => sim_coeff: 1.0
2026-01-16 00:59:14,651 [trainer.py] => sparse_coeff: 0.001
2026-01-16 00:59:14,651 [trainer.py] => repeat: False
2026-01-16 00:59:14,651 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 00:59:14,651 [trainer.py] => num_archetypes: 4
2026-01-16 00:59:14,651 [trainer.py] => augment: 0
2026-01-16 02:04:49,248 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 02:04:49,251 [trainer.py] => dataset: imagenet100
2026-01-16 02:04:49,252 [trainer.py] => shuffle: True
2026-01-16 02:04:49,252 [trainer.py] => init_cls: 10
2026-01-16 02:04:49,252 [trainer.py] => increment: 10
2026-01-16 02:04:49,252 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 02:04:49,252 [trainer.py] => sim: 1
2026-01-16 02:04:49,252 [trainer.py] => epochs: 31
2026-01-16 02:04:49,252 [trainer.py] => lr: 0.01
2026-01-16 02:04:49,255 [trainer.py] => FB_epoch: 51
2026-01-16 02:04:49,255 [trainer.py] => FB_epoch_inc: 31
2026-01-16 02:04:49,255 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 02:04:49,255 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 02:04:49,255 [trainer.py] => pool: 10
2026-01-16 02:04:49,256 [trainer.py] => sg_num: 1
2026-01-16 02:04:49,256 [trainer.py] => gamma: 0.1
2026-01-16 02:04:49,256 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 02:04:49,256 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 02:04:49,256 [trainer.py] => model_name: combined_learner
2026-01-16 02:04:49,256 [trainer.py] => model_size: ViT-B/16
2026-01-16 02:04:49,256 [trainer.py] => convnet_type: none
2026-01-16 02:04:49,256 [trainer.py] => seed: 1993
2026-01-16 02:04:49,256 [trainer.py] => batch_size: 64
2026-01-16 02:04:49,257 [trainer.py] => num_workers: 8
2026-01-16 02:04:49,257 [trainer.py] => model_type: clip
2026-01-16 02:04:49,257 [trainer.py] => division_power: 5
2026-01-16 02:04:49,258 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 02:04:49,260 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 02:04:49,260 [trainer.py] => regularizer: mahalanobis
2026-01-16 02:04:49,260 [trainer.py] => print_freq: 10
2026-01-16 02:04:49,261 [trainer.py] => memory_size: 0
2026-01-16 02:04:49,261 [trainer.py] => k: 10
2026-01-16 02:04:49,261 [trainer.py] => sim_coeff: 1.0
2026-01-16 02:04:49,261 [trainer.py] => sparse_coeff: 0.001
2026-01-16 02:04:49,261 [trainer.py] => repeat: False
2026-01-16 02:04:49,261 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 02:04:49,261 [trainer.py] => num_archetypes: 4
2026-01-16 02:04:49,261 [trainer.py] => augment: 0
2026-01-16 02:05:34,938 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 02:05:34,943 [trainer.py] => dataset: imagenet100
2026-01-16 02:05:34,943 [trainer.py] => shuffle: True
2026-01-16 02:05:34,943 [trainer.py] => init_cls: 10
2026-01-16 02:05:34,943 [trainer.py] => increment: 10
2026-01-16 02:05:34,943 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 02:05:34,944 [trainer.py] => sim: 1
2026-01-16 02:05:34,947 [trainer.py] => epochs: 31
2026-01-16 02:05:34,947 [trainer.py] => lr: 0.01
2026-01-16 02:05:34,947 [trainer.py] => FB_epoch: 51
2026-01-16 02:05:34,947 [trainer.py] => FB_epoch_inc: 31
2026-01-16 02:05:34,948 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 02:05:34,951 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 02:05:34,951 [trainer.py] => pool: 10
2026-01-16 02:05:34,951 [trainer.py] => sg_num: 1
2026-01-16 02:05:34,952 [trainer.py] => gamma: 0.1
2026-01-16 02:05:34,952 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 02:05:34,952 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 02:05:34,952 [trainer.py] => model_name: combined_learner
2026-01-16 02:05:34,952 [trainer.py] => model_size: ViT-B/16
2026-01-16 02:05:34,952 [trainer.py] => convnet_type: none
2026-01-16 02:05:34,952 [trainer.py] => seed: 1993
2026-01-16 02:05:34,953 [trainer.py] => batch_size: 64
2026-01-16 02:05:34,953 [trainer.py] => num_workers: 8
2026-01-16 02:05:34,953 [trainer.py] => model_type: clip
2026-01-16 02:05:34,953 [trainer.py] => division_power: 5
2026-01-16 02:05:34,953 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 02:05:34,953 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 02:05:34,953 [trainer.py] => regularizer: mahalanobis
2026-01-16 02:05:34,953 [trainer.py] => print_freq: 10
2026-01-16 02:05:34,954 [trainer.py] => memory_size: 0
2026-01-16 02:05:34,954 [trainer.py] => k: 10
2026-01-16 02:05:34,954 [trainer.py] => sim_coeff: 1.0
2026-01-16 02:05:34,954 [trainer.py] => sparse_coeff: 0.001
2026-01-16 02:05:34,954 [trainer.py] => repeat: False
2026-01-16 02:05:34,954 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 02:05:34,955 [trainer.py] => num_archetypes: 4
2026-01-16 02:05:34,955 [trainer.py] => augment: 0
2026-01-16 02:06:33,473 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 02:06:33,473 [trainer.py] => dataset: imagenet100
2026-01-16 02:06:33,474 [trainer.py] => shuffle: True
2026-01-16 02:06:33,474 [trainer.py] => init_cls: 10
2026-01-16 02:06:33,474 [trainer.py] => increment: 10
2026-01-16 02:06:33,474 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 02:06:33,474 [trainer.py] => sim: 1
2026-01-16 02:06:33,474 [trainer.py] => epochs: 31
2026-01-16 02:06:33,478 [trainer.py] => lr: 0.01
2026-01-16 02:06:33,478 [trainer.py] => FB_epoch: 51
2026-01-16 02:06:33,479 [trainer.py] => FB_epoch_inc: 31
2026-01-16 02:06:33,479 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 02:06:33,482 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 02:06:33,482 [trainer.py] => pool: 10
2026-01-16 02:06:33,482 [trainer.py] => sg_num: 1
2026-01-16 02:06:33,483 [trainer.py] => gamma: 0.1
2026-01-16 02:06:33,483 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 02:06:33,483 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 02:06:33,483 [trainer.py] => model_name: combined_learner
2026-01-16 02:06:33,483 [trainer.py] => model_size: ViT-B/16
2026-01-16 02:06:33,484 [trainer.py] => convnet_type: none
2026-01-16 02:06:33,484 [trainer.py] => seed: 1993
2026-01-16 02:06:33,484 [trainer.py] => batch_size: 64
2026-01-16 02:06:33,484 [trainer.py] => num_workers: 8
2026-01-16 02:06:33,484 [trainer.py] => model_type: clip
2026-01-16 02:06:33,485 [trainer.py] => division_power: 5
2026-01-16 02:06:33,485 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 02:06:33,485 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 02:06:33,485 [trainer.py] => regularizer: mahalanobis
2026-01-16 02:06:33,485 [trainer.py] => print_freq: 10
2026-01-16 02:06:33,485 [trainer.py] => memory_size: 0
2026-01-16 02:06:33,485 [trainer.py] => k: 10
2026-01-16 02:06:33,486 [trainer.py] => sim_coeff: 1.0
2026-01-16 02:06:33,486 [trainer.py] => sparse_coeff: 0.001
2026-01-16 02:06:33,487 [trainer.py] => repeat: False
2026-01-16 02:06:33,487 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 02:06:33,487 [trainer.py] => num_archetypes: 4
2026-01-16 02:06:33,487 [trainer.py] => augment: 0
2026-01-16 02:06:35,603 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 94, 14, 71, 95, 97, 96, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 98, 0, 88, 27, 18, 93, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 39, 67, 29, 49, 57, 33]
2026-01-16 02:12:00,825 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 02:12:00,825 [trainer.py] => dataset: imagenet100
2026-01-16 02:12:00,825 [trainer.py] => shuffle: True
2026-01-16 02:12:00,825 [trainer.py] => init_cls: 10
2026-01-16 02:12:00,826 [trainer.py] => increment: 10
2026-01-16 02:12:00,826 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 02:12:00,826 [trainer.py] => sim: 1
2026-01-16 02:12:00,830 [trainer.py] => epochs: 31
2026-01-16 02:12:00,830 [trainer.py] => lr: 0.01
2026-01-16 02:12:00,831 [trainer.py] => FB_epoch: 51
2026-01-16 02:12:00,831 [trainer.py] => FB_epoch_inc: 31
2026-01-16 02:12:00,831 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 02:12:00,832 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 02:12:00,832 [trainer.py] => pool: 10
2026-01-16 02:12:00,832 [trainer.py] => sg_num: 1
2026-01-16 02:12:00,832 [trainer.py] => gamma: 0.1
2026-01-16 02:12:00,833 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 02:12:00,833 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 02:12:00,833 [trainer.py] => model_name: combined_learner
2026-01-16 02:12:00,837 [trainer.py] => model_size: ViT-B/16
2026-01-16 02:12:00,837 [trainer.py] => convnet_type: none
2026-01-16 02:12:00,837 [trainer.py] => seed: 1993
2026-01-16 02:12:00,838 [trainer.py] => batch_size: 64
2026-01-16 02:12:00,838 [trainer.py] => num_workers: 8
2026-01-16 02:12:00,838 [trainer.py] => model_type: clip
2026-01-16 02:12:00,839 [trainer.py] => division_power: 5
2026-01-16 02:12:00,839 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 02:12:00,839 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 02:12:00,839 [trainer.py] => regularizer: mahalanobis
2026-01-16 02:12:00,839 [trainer.py] => print_freq: 10
2026-01-16 02:12:00,839 [trainer.py] => memory_size: 0
2026-01-16 02:12:00,839 [trainer.py] => k: 10
2026-01-16 02:12:00,839 [trainer.py] => sim_coeff: 1.0
2026-01-16 02:12:00,839 [trainer.py] => sparse_coeff: 0.001
2026-01-16 02:12:00,839 [trainer.py] => repeat: False
2026-01-16 02:12:00,839 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 02:12:00,840 [trainer.py] => num_archetypes: 4
2026-01-16 02:12:00,840 [trainer.py] => augment: 0
2026-01-16 02:12:02,867 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 94, 14, 71, 95, 97, 96, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 98, 0, 88, 27, 18, 93, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 39, 67, 29, 49, 57, 33]
2026-01-16 10:57:50,118 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 10:57:50,119 [trainer.py] => dataset: imagenet100
2026-01-16 10:57:50,119 [trainer.py] => shuffle: True
2026-01-16 10:57:50,120 [trainer.py] => init_cls: 10
2026-01-16 10:57:50,120 [trainer.py] => increment: 10
2026-01-16 10:57:50,120 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 10:57:50,121 [trainer.py] => sim: 1
2026-01-16 10:57:50,121 [trainer.py] => epochs: 31
2026-01-16 10:57:50,121 [trainer.py] => lr: 0.01
2026-01-16 10:57:50,121 [trainer.py] => FB_epoch: 51
2026-01-16 10:57:50,121 [trainer.py] => FB_epoch_inc: 31
2026-01-16 10:57:50,121 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 10:57:50,121 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 10:57:50,121 [trainer.py] => pool: 10
2026-01-16 10:57:50,122 [trainer.py] => sg_num: 1
2026-01-16 10:57:50,122 [trainer.py] => gamma: 0.1
2026-01-16 10:57:50,122 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 10:57:50,122 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 10:57:50,122 [trainer.py] => model_name: combined_learner
2026-01-16 10:57:50,122 [trainer.py] => model_size: ViT-B/16
2026-01-16 10:57:50,122 [trainer.py] => convnet_type: none
2026-01-16 10:57:50,122 [trainer.py] => seed: 1993
2026-01-16 10:57:50,123 [trainer.py] => batch_size: 64
2026-01-16 10:57:50,123 [trainer.py] => num_workers: 8
2026-01-16 10:57:50,123 [trainer.py] => model_type: clip
2026-01-16 10:57:50,123 [trainer.py] => division_power: 5
2026-01-16 10:57:50,123 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 10:57:50,123 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 10:57:50,124 [trainer.py] => regularizer: mahalanobis
2026-01-16 10:57:50,124 [trainer.py] => print_freq: 10
2026-01-16 10:57:50,124 [trainer.py] => memory_size: 0
2026-01-16 10:57:50,124 [trainer.py] => k: 10
2026-01-16 10:57:50,127 [trainer.py] => sim_coeff: 1.0
2026-01-16 10:57:50,127 [trainer.py] => sparse_coeff: 0.001
2026-01-16 10:57:50,127 [trainer.py] => repeat: False
2026-01-16 10:57:50,127 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 10:57:50,128 [trainer.py] => num_archetypes: 4
2026-01-16 10:57:50,128 [trainer.py] => augment: 0
2026-01-16 10:57:52,399 [data_manager.py] => [13, 22, 8, 6, 10, 15, 23, 12, 14, 19, 21, 11, 5, 0, 18, 2, 4, 20, 9, 7, 16, 3, 24, 17, 1]
2026-01-16 10:59:25,333 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 10:59:25,333 [trainer.py] => dataset: imagenet100
2026-01-16 10:59:25,333 [trainer.py] => shuffle: True
2026-01-16 10:59:25,333 [trainer.py] => init_cls: 10
2026-01-16 10:59:25,333 [trainer.py] => increment: 10
2026-01-16 10:59:25,333 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 10:59:25,334 [trainer.py] => sim: 1
2026-01-16 10:59:25,336 [trainer.py] => epochs: 31
2026-01-16 10:59:25,337 [trainer.py] => lr: 0.01
2026-01-16 10:59:25,337 [trainer.py] => FB_epoch: 51
2026-01-16 10:59:25,337 [trainer.py] => FB_epoch_inc: 31
2026-01-16 10:59:25,337 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 10:59:25,337 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 10:59:25,337 [trainer.py] => pool: 10
2026-01-16 10:59:25,338 [trainer.py] => sg_num: 1
2026-01-16 10:59:25,338 [trainer.py] => gamma: 0.1
2026-01-16 10:59:25,338 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 10:59:25,338 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 10:59:25,338 [trainer.py] => model_name: combined_learner
2026-01-16 10:59:25,340 [trainer.py] => model_size: ViT-B/16
2026-01-16 10:59:25,341 [trainer.py] => convnet_type: none
2026-01-16 10:59:25,341 [trainer.py] => seed: 1993
2026-01-16 10:59:25,341 [trainer.py] => batch_size: 64
2026-01-16 10:59:25,341 [trainer.py] => num_workers: 8
2026-01-16 10:59:25,341 [trainer.py] => model_type: clip
2026-01-16 10:59:25,341 [trainer.py] => division_power: 5
2026-01-16 10:59:25,341 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 10:59:25,341 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 10:59:25,342 [trainer.py] => regularizer: mahalanobis
2026-01-16 10:59:25,342 [trainer.py] => print_freq: 10
2026-01-16 10:59:25,342 [trainer.py] => memory_size: 0
2026-01-16 10:59:25,342 [trainer.py] => k: 10
2026-01-16 10:59:25,342 [trainer.py] => sim_coeff: 1.0
2026-01-16 10:59:25,342 [trainer.py] => sparse_coeff: 0.001
2026-01-16 10:59:25,342 [trainer.py] => repeat: False
2026-01-16 10:59:25,342 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 10:59:25,342 [trainer.py] => num_archetypes: 4
2026-01-16 10:59:25,345 [trainer.py] => augment: 0
2026-01-16 10:59:27,945 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 94, 14, 71, 95, 97, 96, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 98, 0, 88, 27, 18, 93, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 39, 67, 29, 49, 57, 33]
2026-01-16 11:02:32,392 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 11:02:32,392 [trainer.py] => dataset: imagenet100
2026-01-16 11:02:32,392 [trainer.py] => shuffle: True
2026-01-16 11:02:32,392 [trainer.py] => init_cls: 10
2026-01-16 11:02:32,392 [trainer.py] => increment: 10
2026-01-16 11:02:32,392 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 11:02:32,392 [trainer.py] => sim: 1
2026-01-16 11:02:32,392 [trainer.py] => epochs: 31
2026-01-16 11:02:32,392 [trainer.py] => lr: 0.01
2026-01-16 11:02:32,392 [trainer.py] => FB_epoch: 51
2026-01-16 11:02:32,393 [trainer.py] => FB_epoch_inc: 31
2026-01-16 11:02:32,393 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 11:02:32,393 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 11:02:32,393 [trainer.py] => pool: 10
2026-01-16 11:02:32,393 [trainer.py] => sg_num: 1
2026-01-16 11:02:32,393 [trainer.py] => gamma: 0.1
2026-01-16 11:02:32,393 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 11:02:32,393 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 11:02:32,393 [trainer.py] => model_name: combined_learner
2026-01-16 11:02:32,393 [trainer.py] => model_size: ViT-B/16
2026-01-16 11:02:32,393 [trainer.py] => convnet_type: none
2026-01-16 11:02:32,393 [trainer.py] => seed: 1993
2026-01-16 11:02:32,393 [trainer.py] => batch_size: 64
2026-01-16 11:02:32,393 [trainer.py] => num_workers: 8
2026-01-16 11:02:32,393 [trainer.py] => model_type: clip
2026-01-16 11:02:32,393 [trainer.py] => division_power: 5
2026-01-16 11:02:32,393 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 11:02:32,394 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 11:02:32,394 [trainer.py] => regularizer: mahalanobis
2026-01-16 11:02:32,394 [trainer.py] => print_freq: 10
2026-01-16 11:02:32,396 [trainer.py] => memory_size: 0
2026-01-16 11:02:32,397 [trainer.py] => k: 10
2026-01-16 11:02:32,397 [trainer.py] => sim_coeff: 1.0
2026-01-16 11:02:32,397 [trainer.py] => sparse_coeff: 0.001
2026-01-16 11:02:32,397 [trainer.py] => repeat: False
2026-01-16 11:02:32,397 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 11:02:32,397 [trainer.py] => num_archetypes: 4
2026-01-16 11:02:32,397 [trainer.py] => augment: 0
2026-01-16 11:53:12,578 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 11:53:12,579 [trainer.py] => dataset: imagenet100
2026-01-16 11:53:12,579 [trainer.py] => shuffle: True
2026-01-16 11:53:12,583 [trainer.py] => init_cls: 10
2026-01-16 11:53:12,584 [trainer.py] => increment: 10
2026-01-16 11:53:12,584 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 11:53:12,584 [trainer.py] => sim: 1
2026-01-16 11:53:12,585 [trainer.py] => epochs: 31
2026-01-16 11:53:12,585 [trainer.py] => lr: 0.01
2026-01-16 11:53:12,585 [trainer.py] => FB_epoch: 51
2026-01-16 11:53:12,586 [trainer.py] => FB_epoch_inc: 31
2026-01-16 11:53:12,589 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 11:53:12,590 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 11:53:12,590 [trainer.py] => pool: 10
2026-01-16 11:53:12,590 [trainer.py] => sg_num: 1
2026-01-16 11:53:12,591 [trainer.py] => gamma: 0.1
2026-01-16 11:53:12,591 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 11:53:12,591 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 11:53:12,591 [trainer.py] => model_name: combined_learner
2026-01-16 11:53:12,591 [trainer.py] => model_size: ViT-B/16
2026-01-16 11:53:12,591 [trainer.py] => convnet_type: none
2026-01-16 11:53:12,592 [trainer.py] => seed: 1993
2026-01-16 11:53:12,592 [trainer.py] => batch_size: 64
2026-01-16 11:53:12,592 [trainer.py] => num_workers: 12
2026-01-16 11:53:12,592 [trainer.py] => model_type: clip
2026-01-16 11:53:12,592 [trainer.py] => division_power: 5
2026-01-16 11:53:12,592 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 11:53:12,592 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 11:53:12,592 [trainer.py] => regularizer: mahalanobis
2026-01-16 11:53:12,592 [trainer.py] => print_freq: 10
2026-01-16 11:53:12,593 [trainer.py] => memory_size: 0
2026-01-16 11:53:12,593 [trainer.py] => k: 10
2026-01-16 11:53:12,593 [trainer.py] => sim_coeff: 1.0
2026-01-16 11:53:12,593 [trainer.py] => sparse_coeff: 0.001
2026-01-16 11:53:12,593 [trainer.py] => repeat: False
2026-01-16 11:53:12,593 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 11:53:12,593 [trainer.py] => num_archetypes: 4
2026-01-16 11:53:12,593 [trainer.py] => augment: 0
2026-01-16 11:53:15,211 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2026-01-16 11:53:15,418 [SGC.py] => Learning on task 0 (10 new classes): 0-9
2026-01-16 11:53:15,422 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 11:54:43,446 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 11:55:56,131 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 11:55:56,131 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 11:55:56,134 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9]}
2026-01-16 11:55:56,149 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 11:56:38,453 [SGC.py] => Starting model training. Training ALL 2 groups.
2026-01-16 11:56:38,455 [SGC.py] => Unfreezing components for ALL groups: [1, 2]
2026-01-16 11:57:33,255 [SGC.py] => Task: 0, Epoch: 1, Train Loss: 1.178853, Train Acc: 87.8769, Test Acc on New: 92.0000
2026-01-16 11:57:33,278 [SGC.py] => New best accuracy found: 92.00%
2026-01-16 15:36:55,278 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 15:36:55,280 [trainer.py] => dataset: imagenet100
2026-01-16 15:36:55,280 [trainer.py] => shuffle: True
2026-01-16 15:36:55,280 [trainer.py] => init_cls: 10
2026-01-16 15:36:55,280 [trainer.py] => increment: 10
2026-01-16 15:36:55,280 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 15:36:55,280 [trainer.py] => sim: 1
2026-01-16 15:36:55,280 [trainer.py] => epochs: 31
2026-01-16 15:36:55,280 [trainer.py] => lr: 0.01
2026-01-16 15:36:55,280 [trainer.py] => FB_epoch: 51
2026-01-16 15:36:55,280 [trainer.py] => FB_epoch_inc: 31
2026-01-16 15:36:55,280 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 15:36:55,280 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 15:36:55,280 [trainer.py] => pool: 10
2026-01-16 15:36:55,280 [trainer.py] => sg_num: 1
2026-01-16 15:36:55,280 [trainer.py] => gamma: 0.1
2026-01-16 15:36:55,280 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 15:36:55,280 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 15:36:55,280 [trainer.py] => model_name: combined_learner
2026-01-16 15:36:55,280 [trainer.py] => model_size: ViT-B/16
2026-01-16 15:36:55,280 [trainer.py] => convnet_type: none
2026-01-16 15:36:55,280 [trainer.py] => seed: 1993
2026-01-16 15:36:55,280 [trainer.py] => batch_size: 64
2026-01-16 15:36:55,280 [trainer.py] => num_workers: 18
2026-01-16 15:36:55,280 [trainer.py] => model_type: clip
2026-01-16 15:36:55,280 [trainer.py] => division_power: 5
2026-01-16 15:36:55,280 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 15:36:55,281 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 15:36:55,281 [trainer.py] => regularizer: mahalanobis
2026-01-16 15:36:55,281 [trainer.py] => print_freq: 10
2026-01-16 15:36:55,281 [trainer.py] => memory_size: 0
2026-01-16 15:36:55,281 [trainer.py] => k: 10
2026-01-16 15:36:55,281 [trainer.py] => sim_coeff: 1.0
2026-01-16 15:36:55,281 [trainer.py] => sparse_coeff: 0.001
2026-01-16 15:36:55,281 [trainer.py] => repeat: False
2026-01-16 15:36:55,281 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 15:36:55,281 [trainer.py] => num_archetypes: 4
2026-01-16 15:36:55,281 [trainer.py] => augment: 0
2026-01-16 15:45:21,005 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 15:45:21,005 [trainer.py] => dataset: imagenet100
2026-01-16 15:45:21,005 [trainer.py] => shuffle: True
2026-01-16 15:45:21,005 [trainer.py] => init_cls: 10
2026-01-16 15:45:21,005 [trainer.py] => increment: 10
2026-01-16 15:45:21,005 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 15:45:21,005 [trainer.py] => sim: 1
2026-01-16 15:45:21,005 [trainer.py] => epochs: 31
2026-01-16 15:45:21,005 [trainer.py] => lr: 0.01
2026-01-16 15:45:21,005 [trainer.py] => FB_epoch: 51
2026-01-16 15:45:21,005 [trainer.py] => FB_epoch_inc: 31
2026-01-16 15:45:21,005 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 15:45:21,005 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 15:45:21,005 [trainer.py] => pool: 10
2026-01-16 15:45:21,005 [trainer.py] => sg_num: 1
2026-01-16 15:45:21,005 [trainer.py] => gamma: 0.1
2026-01-16 15:45:21,005 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 15:45:21,005 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 15:45:21,005 [trainer.py] => model_name: combined_learner
2026-01-16 15:45:21,005 [trainer.py] => model_size: ViT-B/16
2026-01-16 15:45:21,005 [trainer.py] => convnet_type: none
2026-01-16 15:45:21,005 [trainer.py] => seed: 1993
2026-01-16 15:45:21,005 [trainer.py] => batch_size: 64
2026-01-16 15:45:21,005 [trainer.py] => num_workers: 18
2026-01-16 15:45:21,005 [trainer.py] => model_type: clip
2026-01-16 15:45:21,005 [trainer.py] => division_power: 5
2026-01-16 15:45:21,005 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 15:45:21,005 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 15:45:21,005 [trainer.py] => regularizer: mahalanobis
2026-01-16 15:45:21,005 [trainer.py] => print_freq: 10
2026-01-16 15:45:21,005 [trainer.py] => memory_size: 0
2026-01-16 15:45:21,005 [trainer.py] => k: 10
2026-01-16 15:45:21,005 [trainer.py] => sim_coeff: 1.0
2026-01-16 15:45:21,005 [trainer.py] => sparse_coeff: 0.001
2026-01-16 15:45:21,005 [trainer.py] => repeat: False
2026-01-16 15:45:21,005 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 15:45:21,005 [trainer.py] => num_archetypes: 4
2026-01-16 15:45:21,005 [trainer.py] => augment: 0
2026-01-16 15:46:31,294 [trainer.py] => config: exps/10,10_imagenet100.json
2026-01-16 15:46:31,294 [trainer.py] => dataset: imagenet100
2026-01-16 15:46:31,294 [trainer.py] => shuffle: True
2026-01-16 15:46:31,295 [trainer.py] => init_cls: 10
2026-01-16 15:46:31,295 [trainer.py] => increment: 10
2026-01-16 15:46:31,295 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 15:46:31,295 [trainer.py] => sim: 1
2026-01-16 15:46:31,295 [trainer.py] => epochs: 31
2026-01-16 15:46:31,295 [trainer.py] => lr: 0.01
2026-01-16 15:46:31,295 [trainer.py] => FB_epoch: 51
2026-01-16 15:46:31,295 [trainer.py] => FB_epoch_inc: 31
2026-01-16 15:46:31,295 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 15:46:31,295 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 15:46:31,295 [trainer.py] => pool: 10
2026-01-16 15:46:31,295 [trainer.py] => sg_num: 1
2026-01-16 15:46:31,295 [trainer.py] => gamma: 0.1
2026-01-16 15:46:31,295 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 15:46:31,295 [trainer.py] => prefix: continual-CLIP-IN100
2026-01-16 15:46:31,295 [trainer.py] => model_name: combined_learner
2026-01-16 15:46:31,295 [trainer.py] => model_size: ViT-B/16
2026-01-16 15:46:31,295 [trainer.py] => convnet_type: none
2026-01-16 15:46:31,295 [trainer.py] => seed: 1993
2026-01-16 15:46:31,295 [trainer.py] => batch_size: 64
2026-01-16 15:46:31,295 [trainer.py] => num_workers: 18
2026-01-16 15:46:31,295 [trainer.py] => model_type: clip
2026-01-16 15:46:31,295 [trainer.py] => division_power: 5
2026-01-16 15:46:31,295 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 15:46:31,295 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 15:46:31,295 [trainer.py] => regularizer: mahalanobis
2026-01-16 15:46:31,295 [trainer.py] => print_freq: 10
2026-01-16 15:46:31,295 [trainer.py] => memory_size: 0
2026-01-16 15:46:31,295 [trainer.py] => k: 10
2026-01-16 15:46:31,295 [trainer.py] => sim_coeff: 1.0
2026-01-16 15:46:31,295 [trainer.py] => sparse_coeff: 0.001
2026-01-16 15:46:31,295 [trainer.py] => repeat: False
2026-01-16 15:46:31,295 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 15:46:31,295 [trainer.py] => num_archetypes: 4
2026-01-16 15:46:31,295 [trainer.py] => augment: 0
2026-01-16 15:46:32,957 [data_manager.py] => [68, 56, 78, 8, 23, 84, 90, 65, 74, 76, 40, 89, 3, 92, 55, 9, 26, 80, 43, 38, 58, 70, 77, 1, 85, 19, 17, 50, 28, 53, 13, 81, 45, 82, 6, 59, 83, 16, 15, 44, 91, 41, 72, 60, 79, 52, 20, 10, 31, 54, 37, 95, 14, 71, 96, 98, 97, 2, 64, 66, 42, 22, 35, 86, 24, 34, 87, 21, 99, 0, 88, 27, 18, 94, 11, 12, 47, 25, 30, 46, 62, 69, 36, 61, 7, 63, 75, 5, 32, 4, 51, 48, 73, 93, 39, 67, 29, 49, 57, 33]
2026-01-16 15:46:33,077 [SGC.py] => Learning on task 0 (10 new classes): 0-9
2026-01-16 15:46:33,079 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 15:46:43,841 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 15:46:59,335 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 15:46:59,336 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 15:46:59,336 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9]}
2026-01-16 15:46:59,339 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 15:47:15,045 [SGC.py] => Starting model training. Training ALL 2 groups.
2026-01-16 15:47:15,046 [SGC.py] => Unfreezing components for ALL groups: [1, 2]
2026-01-16 15:47:17,933 [SGC.py] => Task: 0, Epoch: 1, Train Loss: 1.178857, Train Acc: 87.8846, Test Acc on New: 92.0000
2026-01-16 15:47:17,939 [SGC.py] => New best accuracy found: 92.00%
2026-01-16 15:47:35,584 [SGC.py] => Task: 0, Epoch: 11, Train Loss: 0.084563, Train Acc: 97.1385, Test Acc on New: 95.0000
2026-01-16 15:47:35,590 [SGC.py] => New best accuracy found: 95.00%
2026-01-16 15:47:53,077 [SGC.py] => Task: 0, Epoch: 21, Train Loss: 0.066321, Train Acc: 97.7308, Test Acc on New: 95.6000
2026-01-16 15:47:53,083 [SGC.py] => New best accuracy found: 95.60%
2026-01-16 15:48:10,594 [SGC.py] => Task: 0, Epoch: 31, Train Loss: 0.054681, Train Acc: 98.3154, Test Acc on New: 96.2000
2026-01-16 15:48:10,599 [SGC.py] => New best accuracy found: 96.20%
2026-01-16 15:48:28,130 [SGC.py] => Task: 0, Epoch: 41, Train Loss: 0.054184, Train Acc: 98.3077, Test Acc on New: 96.2000
2026-01-16 15:48:46,011 [SGC.py] => Task: 0, Epoch: 51, Train Loss: 0.054086, Train Acc: 98.3154, Test Acc on New: 96.2000
2026-01-16 15:48:46,012 [SGC.py] => Loading best model for task 0 with Test Acc on New: 96.20%
2026-01-16 15:48:47,195 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 15:48:47,195 [SGC.py] => CNN accuracy: {'total': np.float64(96.2), 'group_1': np.float64(96.8), 'group_2': np.float64(95.6), 'old': 0, 'new': np.float64(96.2), 'top1': np.float64(96.2), 'top5': np.float64(100.0), 'grouped': {'total': np.float64(96.2), 'group_1': np.float64(96.8), 'group_2': np.float64(95.6), 'old': 0, 'new': np.float64(96.2), 'top1': np.float64(96.2), 'top5': np.float64(100.0)}}
2026-01-16 15:48:47,195 [trainer.py] => No NME accuracy.
2026-01-16 15:48:47,195 [trainer.py] => CNN: {'total': np.float64(96.2), 'group_1': np.float64(96.8), 'group_2': np.float64(95.6), 'old': 0, 'new': np.float64(96.2), 'top1': np.float64(96.2), 'top5': np.float64(100.0)}
2026-01-16 15:48:47,195 [trainer.py] => CNN top1 curve: [np.float64(96.2)]
2026-01-16 15:48:47,195 [trainer.py] => CNN top5 curve: [np.float64(100.0)]

2026-01-16 15:48:47,195 [trainer.py] => Average Accuracy (CNN): 96.2
2026-01-16 15:48:47,195 [SGC.py] => Learning on task 1 (10 new classes): 10-19
2026-01-16 15:48:47,199 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 15:48:57,584 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 15:49:13,088 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 15:49:13,088 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 15:49:13,090 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19]}
2026-01-16 15:49:13,097 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 15:49:28,326 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 15:49:28,468 [SGC.py] => Starting model training. Training ALL 4 groups.
2026-01-16 15:49:28,469 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4]
2026-01-16 15:49:34,364 [SGC.py] => Task: 1, Epoch: 1, Train Loss: 0.726472, Train Acc: 85.7590, Test Acc on New: 92.8000
2026-01-16 15:49:34,371 [SGC.py] => New best accuracy found: 92.80%
2026-01-16 15:50:27,464 [SGC.py] => Task: 1, Epoch: 11, Train Loss: 0.061106, Train Acc: 98.3588, Test Acc on New: 96.4000
2026-01-16 15:50:27,470 [SGC.py] => New best accuracy found: 96.40%
2026-01-16 15:51:20,231 [SGC.py] => Task: 1, Epoch: 21, Train Loss: 0.046196, Train Acc: 98.9817, Test Acc on New: 96.6000
2026-01-16 15:51:20,237 [SGC.py] => New best accuracy found: 96.60%
2026-01-16 15:52:13,061 [SGC.py] => Task: 1, Epoch: 31, Train Loss: 0.035558, Train Acc: 99.3435, Test Acc on New: 96.0000
2026-01-16 15:52:13,061 [SGC.py] => Loading best model for task 1 with Test Acc on New: 96.60%
2026-01-16 15:52:14,664 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 15:52:14,664 [SGC.py] => CNN accuracy: {'total': np.float64(94.7), 'group_1': np.float64(94.4), 'group_2': np.float64(91.2), 'group_3': np.float64(97.6), 'group_4': np.float64(95.6), 'old': np.float64(92.8), 'new': np.float64(96.6), 'top1': np.float64(94.7), 'top5': np.float64(100.0), 'grouped': {'total': np.float64(94.7), 'group_1': np.float64(94.4), 'group_2': np.float64(91.2), 'group_3': np.float64(97.6), 'group_4': np.float64(95.6), 'old': np.float64(92.8), 'new': np.float64(96.6), 'top1': np.float64(94.7), 'top5': np.float64(100.0)}}
2026-01-16 15:52:14,664 [trainer.py] => No NME accuracy.
2026-01-16 15:52:14,664 [trainer.py] => CNN: {'total': np.float64(94.7), 'group_1': np.float64(94.4), 'group_2': np.float64(91.2), 'group_3': np.float64(97.6), 'group_4': np.float64(95.6), 'old': np.float64(92.8), 'new': np.float64(96.6), 'top1': np.float64(94.7), 'top5': np.float64(100.0)}
2026-01-16 15:52:14,664 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7)]
2026-01-16 15:52:14,664 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0)]

2026-01-16 15:52:14,664 [trainer.py] => Average Accuracy (CNN): 95.45
2026-01-16 15:52:14,664 [SGC.py] => Learning on task 2 (10 new classes): 20-29
2026-01-16 15:52:14,668 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 15:52:25,019 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 15:52:41,305 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 15:52:41,305 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 15:52:41,306 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29]}
2026-01-16 15:52:41,309 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 15:52:57,557 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 15:52:57,609 [SGC.py] => Starting model training. Training ALL 6 groups.
2026-01-16 15:52:57,610 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6]
2026-01-16 15:53:09,099 [SGC.py] => Task: 2, Epoch: 1, Train Loss: 0.486883, Train Acc: 90.5978, Test Acc on New: 95.4000
2026-01-16 15:53:09,106 [SGC.py] => New best accuracy found: 95.40%
2026-01-16 15:54:55,138 [SGC.py] => Task: 2, Epoch: 11, Train Loss: 0.060917, Train Acc: 98.5776, Test Acc on New: 96.6000
2026-01-16 15:54:55,143 [SGC.py] => New best accuracy found: 96.60%
2026-01-16 15:56:40,511 [SGC.py] => Task: 2, Epoch: 21, Train Loss: 0.048378, Train Acc: 98.9755, Test Acc on New: 95.8000
2026-01-16 15:58:26,355 [SGC.py] => Task: 2, Epoch: 31, Train Loss: 0.039457, Train Acc: 99.3062, Test Acc on New: 96.4000
2026-01-16 15:58:26,355 [SGC.py] => Loading best model for task 2 with Test Acc on New: 96.60%
2026-01-16 15:58:28,351 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 15:58:28,351 [SGC.py] => CNN accuracy: {'total': np.float64(94.13), 'group_1': np.float64(95.6), 'group_2': np.float64(89.2), 'group_3': np.float64(92.4), 'group_4': np.float64(94.4), 'group_5': np.float64(96.0), 'group_6': np.float64(97.2), 'old': np.float64(92.9), 'new': np.float64(96.6), 'top1': np.float64(94.13), 'top5': np.float64(99.53), 'grouped': {'total': np.float64(94.13), 'group_1': np.float64(95.6), 'group_2': np.float64(89.2), 'group_3': np.float64(92.4), 'group_4': np.float64(94.4), 'group_5': np.float64(96.0), 'group_6': np.float64(97.2), 'old': np.float64(92.9), 'new': np.float64(96.6), 'top1': np.float64(94.13), 'top5': np.float64(99.53)}}
2026-01-16 15:58:28,351 [trainer.py] => No NME accuracy.
2026-01-16 15:58:28,351 [trainer.py] => CNN: {'total': np.float64(94.13), 'group_1': np.float64(95.6), 'group_2': np.float64(89.2), 'group_3': np.float64(92.4), 'group_4': np.float64(94.4), 'group_5': np.float64(96.0), 'group_6': np.float64(97.2), 'old': np.float64(92.9), 'new': np.float64(96.6), 'top1': np.float64(94.13), 'top5': np.float64(99.53)}
2026-01-16 15:58:28,351 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13)]
2026-01-16 15:58:28,351 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53)]

2026-01-16 15:58:28,351 [trainer.py] => Average Accuracy (CNN): 95.00999999999999
2026-01-16 15:58:28,351 [SGC.py] => Learning on task 3 (10 new classes): 30-39
2026-01-16 15:58:28,355 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 15:58:38,554 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 15:58:54,384 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 15:58:54,384 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 15:58:54,385 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37]}
2026-01-16 15:58:54,390 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 15:59:10,750 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 15:59:10,839 [SGC.py] => Starting model training. Training ALL 8 groups.
2026-01-16 15:59:10,840 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8]
2026-01-16 15:59:29,881 [SGC.py] => Task: 3, Epoch: 1, Train Loss: 0.441803, Train Acc: 89.8995, Test Acc on New: 86.0000
2026-01-16 15:59:29,890 [SGC.py] => New best accuracy found: 86.00%
2026-01-16 16:02:24,097 [SGC.py] => Task: 3, Epoch: 11, Train Loss: 0.124487, Train Acc: 96.1302, Test Acc on New: 86.6000
2026-01-16 16:02:24,104 [SGC.py] => New best accuracy found: 86.60%
2026-01-16 16:05:18,699 [SGC.py] => Task: 3, Epoch: 21, Train Loss: 0.107755, Train Acc: 96.7550, Test Acc on New: 86.6000
2026-01-16 16:08:36,506 [SGC.py] => Task: 3, Epoch: 31, Train Loss: 0.092544, Train Acc: 97.3555, Test Acc on New: 86.6000
2026-01-16 16:08:36,506 [SGC.py] => Loading best model for task 3 with Test Acc on New: 86.60%
2026-01-16 16:08:38,952 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 16:08:38,952 [SGC.py] => CNN accuracy: {'total': np.float64(90.15), 'group_1': np.float64(94.4), 'group_2': np.float64(86.8), 'group_3': np.float64(92.8), 'group_4': np.float64(85.2), 'group_5': np.float64(93.2), 'group_6': np.float64(95.6), 'group_7': np.float64(93.6), 'group_8': np.float64(79.6), 'old': np.float64(91.33), 'new': np.float64(86.6), 'top1': np.float64(90.15), 'top5': np.float64(99.55), 'grouped': {'total': np.float64(90.15), 'group_1': np.float64(94.4), 'group_2': np.float64(86.8), 'group_3': np.float64(92.8), 'group_4': np.float64(85.2), 'group_5': np.float64(93.2), 'group_6': np.float64(95.6), 'group_7': np.float64(93.6), 'group_8': np.float64(79.6), 'old': np.float64(91.33), 'new': np.float64(86.6), 'top1': np.float64(90.15), 'top5': np.float64(99.55)}}
2026-01-16 16:08:38,952 [trainer.py] => No NME accuracy.
2026-01-16 16:08:38,953 [trainer.py] => CNN: {'total': np.float64(90.15), 'group_1': np.float64(94.4), 'group_2': np.float64(86.8), 'group_3': np.float64(92.8), 'group_4': np.float64(85.2), 'group_5': np.float64(93.2), 'group_6': np.float64(95.6), 'group_7': np.float64(93.6), 'group_8': np.float64(79.6), 'old': np.float64(91.33), 'new': np.float64(86.6), 'top1': np.float64(90.15), 'top5': np.float64(99.55)}
2026-01-16 16:08:38,953 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15)]
2026-01-16 16:08:38,953 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55)]

2026-01-16 16:08:38,953 [trainer.py] => Average Accuracy (CNN): 93.79499999999999
2026-01-16 16:08:38,953 [SGC.py] => Learning on task 4 (10 new classes): 40-49
2026-01-16 16:08:38,956 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 16:08:49,151 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 16:09:04,595 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 16:09:04,595 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 16:09:04,596 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37], 9: [40, 41, 42, 48, 49], 10: [43, 44, 45, 46, 47]}
2026-01-16 16:09:04,600 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 16:09:20,745 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 16:09:20,849 [SGC.py] => Starting model training. Training ALL 10 groups.
2026-01-16 16:09:20,850 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2026-01-16 16:09:48,643 [SGC.py] => Task: 4, Epoch: 1, Train Loss: 0.347004, Train Acc: 91.9985, Test Acc on New: 93.4000
2026-01-16 16:09:48,650 [SGC.py] => New best accuracy found: 93.40%
2026-01-16 16:14:10,664 [SGC.py] => Task: 4, Epoch: 11, Train Loss: 0.102979, Train Acc: 97.2055, Test Acc on New: 94.0000
2026-01-16 16:14:10,675 [SGC.py] => New best accuracy found: 94.00%
2026-01-16 16:18:36,073 [SGC.py] => Task: 4, Epoch: 21, Train Loss: 0.086721, Train Acc: 97.7725, Test Acc on New: 94.6000
2026-01-16 16:18:36,080 [SGC.py] => New best accuracy found: 94.60%
2026-01-16 16:22:59,231 [SGC.py] => Task: 4, Epoch: 31, Train Loss: 0.072991, Train Acc: 98.4066, Test Acc on New: 95.0000
2026-01-16 16:22:59,237 [SGC.py] => New best accuracy found: 95.00%
2026-01-16 16:22:59,237 [SGC.py] => Loading best model for task 4 with Test Acc on New: 95.00%
2026-01-16 16:23:02,204 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 16:23:02,204 [SGC.py] => CNN accuracy: {'total': np.float64(90.0), 'group_1': np.float64(93.6), 'group_2': np.float64(84.0), 'group_3': np.float64(92.4), 'group_4': np.float64(86.0), 'group_5': np.float64(91.6), 'group_6': np.float64(92.8), 'group_7': np.float64(91.6), 'group_8': np.float64(78.0), 'group_9': np.float64(94.0), 'group_10': np.float64(96.0), 'old': np.float64(88.75), 'new': np.float64(95.0), 'top1': np.float64(90.0), 'top5': np.float64(99.44), 'grouped': {'total': np.float64(90.0), 'group_1': np.float64(93.6), 'group_2': np.float64(84.0), 'group_3': np.float64(92.4), 'group_4': np.float64(86.0), 'group_5': np.float64(91.6), 'group_6': np.float64(92.8), 'group_7': np.float64(91.6), 'group_8': np.float64(78.0), 'group_9': np.float64(94.0), 'group_10': np.float64(96.0), 'old': np.float64(88.75), 'new': np.float64(95.0), 'top1': np.float64(90.0), 'top5': np.float64(99.44)}}
2026-01-16 16:23:02,204 [trainer.py] => No NME accuracy.
2026-01-16 16:23:02,204 [trainer.py] => CNN: {'total': np.float64(90.0), 'group_1': np.float64(93.6), 'group_2': np.float64(84.0), 'group_3': np.float64(92.4), 'group_4': np.float64(86.0), 'group_5': np.float64(91.6), 'group_6': np.float64(92.8), 'group_7': np.float64(91.6), 'group_8': np.float64(78.0), 'group_9': np.float64(94.0), 'group_10': np.float64(96.0), 'old': np.float64(88.75), 'new': np.float64(95.0), 'top1': np.float64(90.0), 'top5': np.float64(99.44)}
2026-01-16 16:23:02,204 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15), np.float64(90.0)]
2026-01-16 16:23:02,204 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55), np.float64(99.44)]

2026-01-16 16:23:02,204 [trainer.py] => Average Accuracy (CNN): 93.03599999999999
2026-01-16 16:23:02,204 [SGC.py] => Learning on task 5 (10 new classes): 50-59
2026-01-16 16:23:02,208 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 16:23:12,527 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 16:23:28,002 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 16:23:28,002 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 16:23:28,003 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37], 9: [40, 41, 42, 48, 49], 10: [43, 44, 45, 46, 47], 11: [50, 51, 53, 55, 59], 12: [52, 54, 56, 57, 58]}
2026-01-16 16:23:28,053 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 16:23:43,815 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 16:23:44,086 [SGC.py] => Starting model training. Training ALL 12 groups.
2026-01-16 16:23:44,087 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
2026-01-16 16:24:21,671 [SGC.py] => Task: 5, Epoch: 1, Train Loss: 0.334394, Train Acc: 92.4842, Test Acc on New: 91.2000
2026-01-16 16:24:21,677 [SGC.py] => New best accuracy found: 91.20%
2026-01-16 16:31:49,306 [SGC.py] => Task: 5, Epoch: 11, Train Loss: 0.102024, Train Acc: 97.2747, Test Acc on New: 95.2000
2026-01-16 16:31:49,312 [SGC.py] => New best accuracy found: 95.20%
2026-01-16 16:41:16,780 [SGC.py] => Task: 5, Epoch: 21, Train Loss: 0.083906, Train Acc: 97.9510, Test Acc on New: 95.2000
2026-01-16 16:48:57,943 [SGC.py] => Task: 5, Epoch: 31, Train Loss: 0.069999, Train Acc: 98.4608, Test Acc on New: 95.2000
2026-01-16 16:48:57,943 [SGC.py] => Loading best model for task 5 with Test Acc on New: 95.20%
2026-01-16 16:49:01,431 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 16:49:01,435 [SGC.py] => CNN accuracy: {'total': np.float64(90.83), 'group_1': np.float64(92.8), 'group_2': np.float64(86.4), 'group_3': np.float64(90.0), 'group_4': np.float64(86.4), 'group_5': np.float64(92.0), 'group_6': np.float64(95.6), 'group_7': np.float64(91.6), 'group_8': np.float64(76.4), 'group_9': np.float64(92.0), 'group_10': np.float64(96.4), 'group_11': np.float64(94.0), 'group_12': np.float64(96.4), 'old': np.float64(89.96), 'new': np.float64(95.2), 'top1': np.float64(90.83), 'top5': np.float64(99.4), 'grouped': {'total': np.float64(90.83), 'group_1': np.float64(92.8), 'group_2': np.float64(86.4), 'group_3': np.float64(90.0), 'group_4': np.float64(86.4), 'group_5': np.float64(92.0), 'group_6': np.float64(95.6), 'group_7': np.float64(91.6), 'group_8': np.float64(76.4), 'group_9': np.float64(92.0), 'group_10': np.float64(96.4), 'group_11': np.float64(94.0), 'group_12': np.float64(96.4), 'old': np.float64(89.96), 'new': np.float64(95.2), 'top1': np.float64(90.83), 'top5': np.float64(99.4)}}
2026-01-16 16:49:01,435 [trainer.py] => No NME accuracy.
2026-01-16 16:49:01,435 [trainer.py] => CNN: {'total': np.float64(90.83), 'group_1': np.float64(92.8), 'group_2': np.float64(86.4), 'group_3': np.float64(90.0), 'group_4': np.float64(86.4), 'group_5': np.float64(92.0), 'group_6': np.float64(95.6), 'group_7': np.float64(91.6), 'group_8': np.float64(76.4), 'group_9': np.float64(92.0), 'group_10': np.float64(96.4), 'group_11': np.float64(94.0), 'group_12': np.float64(96.4), 'old': np.float64(89.96), 'new': np.float64(95.2), 'top1': np.float64(90.83), 'top5': np.float64(99.4)}
2026-01-16 16:49:01,435 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15), np.float64(90.0), np.float64(90.83)]
2026-01-16 16:49:01,435 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55), np.float64(99.44), np.float64(99.4)]

2026-01-16 16:49:01,435 [trainer.py] => Average Accuracy (CNN): 92.66833333333334
2026-01-16 16:49:01,435 [SGC.py] => Learning on task 6 (10 new classes): 60-69
2026-01-16 16:49:01,439 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 16:49:12,841 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 16:49:29,606 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 16:49:29,606 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 16:49:29,607 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37], 9: [40, 41, 42, 48, 49], 10: [43, 44, 45, 46, 47], 11: [50, 51, 53, 55, 59], 12: [52, 54, 56, 57, 58], 13: [60, 63, 64, 67, 68], 14: [61, 62, 65, 66, 69]}
2026-01-16 16:49:29,695 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 16:49:46,393 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 16:49:46,734 [SGC.py] => Starting model training. Training ALL 14 groups.
2026-01-16 16:49:46,735 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
2026-01-16 16:50:48,792 [SGC.py] => Task: 6, Epoch: 1, Train Loss: 0.315322, Train Acc: 92.1384, Test Acc on New: 87.2000
2026-01-16 16:50:48,800 [SGC.py] => New best accuracy found: 87.20%
2026-01-16 17:00:17,167 [SGC.py] => Task: 6, Epoch: 11, Train Loss: 0.128480, Train Acc: 96.3948, Test Acc on New: 88.0000
2026-01-16 17:00:17,173 [SGC.py] => New best accuracy found: 88.00%
2026-01-16 17:09:32,406 [SGC.py] => Task: 6, Epoch: 21, Train Loss: 0.109714, Train Acc: 97.1194, Test Acc on New: 88.4000
2026-01-16 17:09:32,412 [SGC.py] => New best accuracy found: 88.40%
2026-01-16 17:18:38,518 [SGC.py] => Task: 6, Epoch: 31, Train Loss: 0.094145, Train Acc: 97.6885, Test Acc on New: 87.4000
2026-01-16 17:18:38,518 [SGC.py] => Loading best model for task 6 with Test Acc on New: 88.40%
2026-01-16 17:18:42,229 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 17:18:42,234 [SGC.py] => CNN accuracy: {'total': np.float64(88.4), 'group_1': np.float64(89.6), 'group_2': np.float64(84.4), 'group_3': np.float64(89.2), 'group_4': np.float64(81.2), 'group_5': np.float64(92.4), 'group_6': np.float64(94.4), 'group_7': np.float64(89.6), 'group_8': np.float64(74.8), 'group_9': np.float64(84.8), 'group_10': np.float64(95.2), 'group_11': np.float64(90.0), 'group_12': np.float64(95.2), 'group_13': np.float64(92.0), 'group_14': np.float64(84.8), 'old': np.float64(88.4), 'new': np.float64(88.4), 'top1': np.float64(88.4), 'top5': np.float64(99.17), 'grouped': {'total': np.float64(88.4), 'group_1': np.float64(89.6), 'group_2': np.float64(84.4), 'group_3': np.float64(89.2), 'group_4': np.float64(81.2), 'group_5': np.float64(92.4), 'group_6': np.float64(94.4), 'group_7': np.float64(89.6), 'group_8': np.float64(74.8), 'group_9': np.float64(84.8), 'group_10': np.float64(95.2), 'group_11': np.float64(90.0), 'group_12': np.float64(95.2), 'group_13': np.float64(92.0), 'group_14': np.float64(84.8), 'old': np.float64(88.4), 'new': np.float64(88.4), 'top1': np.float64(88.4), 'top5': np.float64(99.17)}}
2026-01-16 17:18:42,234 [trainer.py] => No NME accuracy.
2026-01-16 17:18:42,234 [trainer.py] => CNN: {'total': np.float64(88.4), 'group_1': np.float64(89.6), 'group_2': np.float64(84.4), 'group_3': np.float64(89.2), 'group_4': np.float64(81.2), 'group_5': np.float64(92.4), 'group_6': np.float64(94.4), 'group_7': np.float64(89.6), 'group_8': np.float64(74.8), 'group_9': np.float64(84.8), 'group_10': np.float64(95.2), 'group_11': np.float64(90.0), 'group_12': np.float64(95.2), 'group_13': np.float64(92.0), 'group_14': np.float64(84.8), 'old': np.float64(88.4), 'new': np.float64(88.4), 'top1': np.float64(88.4), 'top5': np.float64(99.17)}
2026-01-16 17:18:42,234 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15), np.float64(90.0), np.float64(90.83), np.float64(88.4)]
2026-01-16 17:18:42,234 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55), np.float64(99.44), np.float64(99.4), np.float64(99.17)]

2026-01-16 17:18:42,234 [trainer.py] => Average Accuracy (CNN): 92.05857142857143
2026-01-16 17:18:42,234 [SGC.py] => Learning on task 7 (10 new classes): 70-79
2026-01-16 17:18:42,238 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 17:18:52,982 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 17:19:07,795 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 17:19:07,795 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 17:19:07,795 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37], 9: [40, 41, 42, 48, 49], 10: [43, 44, 45, 46, 47], 11: [50, 51, 53, 55, 59], 12: [52, 54, 56, 57, 58], 13: [60, 63, 64, 67, 68], 14: [61, 62, 65, 66, 69], 15: [70, 71, 72, 75, 79], 16: [73, 74, 76, 77, 78]}
2026-01-16 17:19:07,803 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 17:19:23,810 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 17:19:23,993 [SGC.py] => Starting model training. Training ALL 16 groups.
2026-01-16 17:19:23,993 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2026-01-16 17:20:31,749 [SGC.py] => Task: 7, Epoch: 1, Train Loss: 0.330419, Train Acc: 91.9389, Test Acc on New: 86.4000
2026-01-16 17:20:31,757 [SGC.py] => New best accuracy found: 86.40%
2026-01-16 17:31:29,794 [SGC.py] => Task: 7, Epoch: 11, Train Loss: 0.132274, Train Acc: 96.3438, Test Acc on New: 89.6000
2026-01-16 17:31:29,800 [SGC.py] => New best accuracy found: 89.60%
2026-01-16 17:42:34,196 [SGC.py] => Task: 7, Epoch: 21, Train Loss: 0.113417, Train Acc: 97.0189, Test Acc on New: 88.2000
2026-01-16 17:53:39,488 [SGC.py] => Task: 7, Epoch: 31, Train Loss: 0.096694, Train Acc: 97.6577, Test Acc on New: 89.4000
2026-01-16 17:53:39,488 [SGC.py] => Loading best model for task 7 with Test Acc on New: 89.60%
2026-01-16 17:53:43,452 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 17:53:43,453 [SGC.py] => CNN accuracy: {'total': np.float64(87.55), 'group_1': np.float64(90.0), 'group_2': np.float64(82.4), 'group_3': np.float64(90.0), 'group_4': np.float64(82.0), 'group_5': np.float64(92.4), 'group_6': np.float64(88.8), 'group_7': np.float64(90.4), 'group_8': np.float64(72.8), 'group_9': np.float64(83.6), 'group_10': np.float64(96.4), 'group_11': np.float64(92.0), 'group_12': np.float64(94.0), 'group_13': np.float64(86.8), 'group_14': np.float64(80.0), 'group_15': np.float64(91.6), 'group_16': np.float64(87.6), 'old': np.float64(87.26), 'new': np.float64(89.6), 'top1': np.float64(87.55), 'top5': np.float64(99.18), 'grouped': {'total': np.float64(87.55), 'group_1': np.float64(90.0), 'group_2': np.float64(82.4), 'group_3': np.float64(90.0), 'group_4': np.float64(82.0), 'group_5': np.float64(92.4), 'group_6': np.float64(88.8), 'group_7': np.float64(90.4), 'group_8': np.float64(72.8), 'group_9': np.float64(83.6), 'group_10': np.float64(96.4), 'group_11': np.float64(92.0), 'group_12': np.float64(94.0), 'group_13': np.float64(86.8), 'group_14': np.float64(80.0), 'group_15': np.float64(91.6), 'group_16': np.float64(87.6), 'old': np.float64(87.26), 'new': np.float64(89.6), 'top1': np.float64(87.55), 'top5': np.float64(99.18)}}
2026-01-16 17:53:43,453 [trainer.py] => No NME accuracy.
2026-01-16 17:53:43,453 [trainer.py] => CNN: {'total': np.float64(87.55), 'group_1': np.float64(90.0), 'group_2': np.float64(82.4), 'group_3': np.float64(90.0), 'group_4': np.float64(82.0), 'group_5': np.float64(92.4), 'group_6': np.float64(88.8), 'group_7': np.float64(90.4), 'group_8': np.float64(72.8), 'group_9': np.float64(83.6), 'group_10': np.float64(96.4), 'group_11': np.float64(92.0), 'group_12': np.float64(94.0), 'group_13': np.float64(86.8), 'group_14': np.float64(80.0), 'group_15': np.float64(91.6), 'group_16': np.float64(87.6), 'old': np.float64(87.26), 'new': np.float64(89.6), 'top1': np.float64(87.55), 'top5': np.float64(99.18)}
2026-01-16 17:53:43,453 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15), np.float64(90.0), np.float64(90.83), np.float64(88.4), np.float64(87.55)]
2026-01-16 17:53:43,453 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55), np.float64(99.44), np.float64(99.4), np.float64(99.17), np.float64(99.18)]

2026-01-16 17:53:43,453 [trainer.py] => Average Accuracy (CNN): 91.49499999999999
2026-01-16 17:53:43,453 [SGC.py] => Learning on task 8 (10 new classes): 80-89
2026-01-16 17:53:43,457 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 17:53:53,839 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 17:54:08,524 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 17:54:08,524 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 17:54:08,525 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37], 9: [40, 41, 42, 48, 49], 10: [43, 44, 45, 46, 47], 11: [50, 51, 53, 55, 59], 12: [52, 54, 56, 57, 58], 13: [60, 63, 64, 67, 68], 14: [61, 62, 65, 66, 69], 15: [70, 71, 72, 75, 79], 16: [73, 74, 76, 77, 78], 17: [80, 83, 86, 88, 89], 18: [81, 82, 84, 85, 87]}
2026-01-16 17:54:08,564 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 17:54:24,308 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 17:54:24,519 [SGC.py] => Starting model training. Training ALL 18 groups.
2026-01-16 17:54:24,519 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
2026-01-16 17:55:46,438 [SGC.py] => Task: 8, Epoch: 1, Train Loss: 0.305125, Train Acc: 92.2390, Test Acc on New: 88.0000
2026-01-16 17:55:46,445 [SGC.py] => New best accuracy found: 88.00%
2026-01-16 18:09:09,141 [SGC.py] => Task: 8, Epoch: 11, Train Loss: 0.133934, Train Acc: 96.3242, Test Acc on New: 92.4000
2026-01-16 18:09:09,148 [SGC.py] => New best accuracy found: 92.40%
2026-01-16 18:22:35,831 [SGC.py] => Task: 8, Epoch: 21, Train Loss: 0.114647, Train Acc: 97.0254, Test Acc on New: 93.4000
2026-01-16 18:22:35,838 [SGC.py] => New best accuracy found: 93.40%
2026-01-16 18:36:00,248 [SGC.py] => Task: 8, Epoch: 31, Train Loss: 0.098066, Train Acc: 97.7042, Test Acc on New: 93.4000
2026-01-16 18:36:00,248 [SGC.py] => Loading best model for task 8 with Test Acc on New: 93.40%
2026-01-16 18:36:04,831 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 18:36:04,835 [SGC.py] => CNN accuracy: {'total': np.float64(87.29), 'group_1': np.float64(85.2), 'group_2': np.float64(84.0), 'group_3': np.float64(87.6), 'group_4': np.float64(80.4), 'group_5': np.float64(91.6), 'group_6': np.float64(91.6), 'group_7': np.float64(87.6), 'group_8': np.float64(75.2), 'group_9': np.float64(86.4), 'group_10': np.float64(95.2), 'group_11': np.float64(90.8), 'group_12': np.float64(92.0), 'group_13': np.float64(86.4), 'group_14': np.float64(76.4), 'group_15': np.float64(89.6), 'group_16': np.float64(84.4), 'group_17': np.float64(96.4), 'group_18': np.float64(90.4), 'old': np.float64(86.52), 'new': np.float64(93.4), 'top1': np.float64(87.29), 'top5': np.float64(98.78), 'grouped': {'total': np.float64(87.29), 'group_1': np.float64(85.2), 'group_2': np.float64(84.0), 'group_3': np.float64(87.6), 'group_4': np.float64(80.4), 'group_5': np.float64(91.6), 'group_6': np.float64(91.6), 'group_7': np.float64(87.6), 'group_8': np.float64(75.2), 'group_9': np.float64(86.4), 'group_10': np.float64(95.2), 'group_11': np.float64(90.8), 'group_12': np.float64(92.0), 'group_13': np.float64(86.4), 'group_14': np.float64(76.4), 'group_15': np.float64(89.6), 'group_16': np.float64(84.4), 'group_17': np.float64(96.4), 'group_18': np.float64(90.4), 'old': np.float64(86.52), 'new': np.float64(93.4), 'top1': np.float64(87.29), 'top5': np.float64(98.78)}}
2026-01-16 18:36:04,835 [trainer.py] => No NME accuracy.
2026-01-16 18:36:04,835 [trainer.py] => CNN: {'total': np.float64(87.29), 'group_1': np.float64(85.2), 'group_2': np.float64(84.0), 'group_3': np.float64(87.6), 'group_4': np.float64(80.4), 'group_5': np.float64(91.6), 'group_6': np.float64(91.6), 'group_7': np.float64(87.6), 'group_8': np.float64(75.2), 'group_9': np.float64(86.4), 'group_10': np.float64(95.2), 'group_11': np.float64(90.8), 'group_12': np.float64(92.0), 'group_13': np.float64(86.4), 'group_14': np.float64(76.4), 'group_15': np.float64(89.6), 'group_16': np.float64(84.4), 'group_17': np.float64(96.4), 'group_18': np.float64(90.4), 'old': np.float64(86.52), 'new': np.float64(93.4), 'top1': np.float64(87.29), 'top5': np.float64(98.78)}
2026-01-16 18:36:04,835 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15), np.float64(90.0), np.float64(90.83), np.float64(88.4), np.float64(87.55), np.float64(87.29)]
2026-01-16 18:36:04,835 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55), np.float64(99.44), np.float64(99.4), np.float64(99.17), np.float64(99.18), np.float64(98.78)]

2026-01-16 18:36:04,836 [trainer.py] => Average Accuracy (CNN): 91.02777777777777
2026-01-16 18:36:04,836 [SGC.py] => Learning on task 9 (10 new classes): 90-99
2026-01-16 18:36:04,840 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 18:36:15,335 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 18:36:32,438 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 18:36:32,438 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 18:36:32,438 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 4, 7], 2: [1, 5, 6, 8, 9], 3: [10, 11, 12, 14, 16], 4: [13, 15, 17, 18, 19], 5: [20, 21, 24, 25, 27], 6: [22, 23, 26, 28, 29], 7: [30, 31, 34, 38, 39], 8: [32, 33, 35, 36, 37], 9: [40, 41, 42, 48, 49], 10: [43, 44, 45, 46, 47], 11: [50, 51, 53, 55, 59], 12: [52, 54, 56, 57, 58], 13: [60, 63, 64, 67, 68], 14: [61, 62, 65, 66, 69], 15: [70, 71, 72, 75, 79], 16: [73, 74, 76, 77, 78], 17: [80, 83, 86, 88, 89], 18: [81, 82, 84, 85, 87], 19: [90, 92, 94, 96, 98], 20: [91, 93, 95, 97, 99]}
2026-01-16 18:36:32,448 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 18:36:49,366 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 18:36:49,608 [SGC.py] => Starting model training. Training ALL 20 groups.
2026-01-16 18:36:49,609 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
2026-01-16 18:38:26,110 [SGC.py] => Task: 9, Epoch: 1, Train Loss: 0.360567, Train Acc: 90.8468, Test Acc on New: 72.8000
2026-01-16 18:38:26,117 [SGC.py] => New best accuracy found: 72.80%
2026-01-16 18:54:24,146 [SGC.py] => Task: 9, Epoch: 11, Train Loss: 0.173372, Train Acc: 95.0739, Test Acc on New: 81.4000
2026-01-16 18:54:24,153 [SGC.py] => New best accuracy found: 81.40%
2026-01-16 19:15:51,928 [SGC.py] => Task: 9, Epoch: 21, Train Loss: 0.151785, Train Acc: 95.8243, Test Acc on New: 79.8000
2026-01-16 19:34:36,593 [SGC.py] => Task: 9, Epoch: 31, Train Loss: 0.131083, Train Acc: 96.6389, Test Acc on New: 81.4000
2026-01-16 19:34:36,593 [SGC.py] => Loading best model for task 9 with Test Acc on New: 81.40%
2026-01-16 19:34:41,638 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 19:34:41,642 [SGC.py] => CNN accuracy: {'total': np.float64(85.62), 'group_1': np.float64(84.4), 'group_2': np.float64(83.6), 'group_3': np.float64(85.6), 'group_4': np.float64(77.2), 'group_5': np.float64(82.8), 'group_6': np.float64(90.0), 'group_7': np.float64(88.8), 'group_8': np.float64(76.4), 'group_9': np.float64(85.2), 'group_10': np.float64(93.6), 'group_11': np.float64(89.6), 'group_12': np.float64(93.2), 'group_13': np.float64(86.8), 'group_14': np.float64(78.0), 'group_15': np.float64(90.8), 'group_16': np.float64(81.6), 'group_17': np.float64(94.4), 'group_18': np.float64(87.6), 'group_19': np.float64(77.2), 'group_20': np.float64(85.6), 'old': np.float64(86.09), 'new': np.float64(81.4), 'top1': np.float64(85.62), 'top5': np.float64(98.42), 'grouped': {'total': np.float64(85.62), 'group_1': np.float64(84.4), 'group_2': np.float64(83.6), 'group_3': np.float64(85.6), 'group_4': np.float64(77.2), 'group_5': np.float64(82.8), 'group_6': np.float64(90.0), 'group_7': np.float64(88.8), 'group_8': np.float64(76.4), 'group_9': np.float64(85.2), 'group_10': np.float64(93.6), 'group_11': np.float64(89.6), 'group_12': np.float64(93.2), 'group_13': np.float64(86.8), 'group_14': np.float64(78.0), 'group_15': np.float64(90.8), 'group_16': np.float64(81.6), 'group_17': np.float64(94.4), 'group_18': np.float64(87.6), 'group_19': np.float64(77.2), 'group_20': np.float64(85.6), 'old': np.float64(86.09), 'new': np.float64(81.4), 'top1': np.float64(85.62), 'top5': np.float64(98.42)}}
2026-01-16 19:34:41,642 [trainer.py] => No NME accuracy.
2026-01-16 19:34:41,642 [trainer.py] => CNN: {'total': np.float64(85.62), 'group_1': np.float64(84.4), 'group_2': np.float64(83.6), 'group_3': np.float64(85.6), 'group_4': np.float64(77.2), 'group_5': np.float64(82.8), 'group_6': np.float64(90.0), 'group_7': np.float64(88.8), 'group_8': np.float64(76.4), 'group_9': np.float64(85.2), 'group_10': np.float64(93.6), 'group_11': np.float64(89.6), 'group_12': np.float64(93.2), 'group_13': np.float64(86.8), 'group_14': np.float64(78.0), 'group_15': np.float64(90.8), 'group_16': np.float64(81.6), 'group_17': np.float64(94.4), 'group_18': np.float64(87.6), 'group_19': np.float64(77.2), 'group_20': np.float64(85.6), 'old': np.float64(86.09), 'new': np.float64(81.4), 'top1': np.float64(85.62), 'top5': np.float64(98.42)}
2026-01-16 19:34:41,642 [trainer.py] => CNN top1 curve: [np.float64(96.2), np.float64(94.7), np.float64(94.13), np.float64(90.15), np.float64(90.0), np.float64(90.83), np.float64(88.4), np.float64(87.55), np.float64(87.29), np.float64(85.62)]
2026-01-16 19:34:41,642 [trainer.py] => CNN top5 curve: [np.float64(100.0), np.float64(100.0), np.float64(99.53), np.float64(99.55), np.float64(99.44), np.float64(99.4), np.float64(99.17), np.float64(99.18), np.float64(98.78), np.float64(98.42)]

2026-01-16 19:34:41,642 [trainer.py] => Average Accuracy (CNN): 90.487
