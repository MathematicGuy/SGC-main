2026-01-16 00:28:15,410 [trainer.py] => config: exps/10,10_imagenet-r.json
2026-01-16 00:28:15,410 [trainer.py] => dataset: imagenet-r
2026-01-16 00:28:15,410 [trainer.py] => shuffle: True
2026-01-16 00:28:15,410 [trainer.py] => init_cls: 10
2026-01-16 00:28:15,410 [trainer.py] => increment: 10
2026-01-16 00:28:15,421 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 00:28:15,421 [trainer.py] => sim: 1
2026-01-16 00:28:15,423 [trainer.py] => epochs: 31
2026-01-16 00:28:15,423 [trainer.py] => lr: 0.01
2026-01-16 00:28:15,423 [trainer.py] => FB_epoch: 51
2026-01-16 00:28:15,423 [trainer.py] => FB_epoch_inc: 31
2026-01-16 00:28:15,423 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 00:28:15,423 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 00:28:15,423 [trainer.py] => pool: 10
2026-01-16 00:28:15,423 [trainer.py] => sg_num: 1
2026-01-16 00:28:15,423 [trainer.py] => gamma: 0.1
2026-01-16 00:28:15,423 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 00:28:15,423 [trainer.py] => prefix: continual-CLIP-INR
2026-01-16 00:28:15,423 [trainer.py] => model_name: combined_learner
2026-01-16 00:28:15,423 [trainer.py] => model_size: ViT-B/16
2026-01-16 00:28:15,423 [trainer.py] => convnet_type: none
2026-01-16 00:28:15,423 [trainer.py] => seed: 1993
2026-01-16 00:28:15,426 [trainer.py] => batch_size: 64
2026-01-16 00:28:15,426 [trainer.py] => num_workers: 8
2026-01-16 00:28:15,426 [trainer.py] => model_type: clip
2026-01-16 00:28:15,426 [trainer.py] => division_power: 5
2026-01-16 00:28:15,430 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 00:28:15,430 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 00:28:15,430 [trainer.py] => regularizer: mahalanobis
2026-01-16 00:28:15,430 [trainer.py] => print_freq: 10
2026-01-16 00:28:15,430 [trainer.py] => memory_size: 0
2026-01-16 00:28:15,430 [trainer.py] => k: 10
2026-01-16 00:28:15,430 [trainer.py] => sim_coeff: 1.0
2026-01-16 00:28:15,430 [trainer.py] => sparse_coeff: 0.001
2026-01-16 00:28:15,430 [trainer.py] => repeat: False
2026-01-16 00:28:15,430 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 00:28:15,430 [trainer.py] => num_archetypes: 4
2026-01-16 00:28:15,430 [trainer.py] => augment: 0
2026-01-16 00:29:51,636 [trainer.py] => config: exps/10,10_imagenet-r.json
2026-01-16 00:29:51,636 [trainer.py] => dataset: imagenet-r
2026-01-16 00:29:51,636 [trainer.py] => shuffle: True
2026-01-16 00:29:51,636 [trainer.py] => init_cls: 10
2026-01-16 00:29:51,636 [trainer.py] => increment: 10
2026-01-16 00:29:51,636 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 00:29:51,636 [trainer.py] => sim: 1
2026-01-16 00:29:51,644 [trainer.py] => epochs: 31
2026-01-16 00:29:51,644 [trainer.py] => lr: 0.01
2026-01-16 00:29:51,644 [trainer.py] => FB_epoch: 51
2026-01-16 00:29:51,644 [trainer.py] => FB_epoch_inc: 31
2026-01-16 00:29:51,644 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 00:29:51,644 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 00:29:51,644 [trainer.py] => pool: 10
2026-01-16 00:29:51,644 [trainer.py] => sg_num: 1
2026-01-16 00:29:51,644 [trainer.py] => gamma: 0.1
2026-01-16 00:29:51,644 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 00:29:51,644 [trainer.py] => prefix: continual-CLIP-INR
2026-01-16 00:29:51,644 [trainer.py] => model_name: combined_learner
2026-01-16 00:29:51,644 [trainer.py] => model_size: ViT-B/16
2026-01-16 00:29:51,644 [trainer.py] => convnet_type: none
2026-01-16 00:29:51,644 [trainer.py] => seed: 1993
2026-01-16 00:29:51,644 [trainer.py] => batch_size: 64
2026-01-16 00:29:51,644 [trainer.py] => num_workers: 8
2026-01-16 00:29:51,644 [trainer.py] => model_type: clip
2026-01-16 00:29:51,644 [trainer.py] => division_power: 5
2026-01-16 00:29:51,644 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 00:29:51,644 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 00:29:51,644 [trainer.py] => regularizer: mahalanobis
2026-01-16 00:29:51,644 [trainer.py] => print_freq: 10
2026-01-16 00:29:51,644 [trainer.py] => memory_size: 0
2026-01-16 00:29:51,648 [trainer.py] => k: 10
2026-01-16 00:29:51,648 [trainer.py] => sim_coeff: 1.0
2026-01-16 00:29:51,648 [trainer.py] => sparse_coeff: 0.001
2026-01-16 00:29:51,648 [trainer.py] => repeat: False
2026-01-16 00:29:51,648 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 00:29:51,648 [trainer.py] => num_archetypes: 4
2026-01-16 00:29:51,648 [trainer.py] => augment: 0
2026-01-16 00:55:34,930 [trainer.py] => config: exps/10,10_imagenet-r.json
2026-01-16 00:55:34,930 [trainer.py] => dataset: imagenet-r
2026-01-16 00:55:34,930 [trainer.py] => shuffle: True
2026-01-16 00:55:34,931 [trainer.py] => init_cls: 10
2026-01-16 00:55:34,937 [trainer.py] => increment: 10
2026-01-16 00:55:34,938 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 00:55:34,938 [trainer.py] => sim: 1
2026-01-16 00:55:34,938 [trainer.py] => epochs: 31
2026-01-16 00:55:34,938 [trainer.py] => lr: 0.01
2026-01-16 00:55:34,938 [trainer.py] => FB_epoch: 51
2026-01-16 00:55:34,938 [trainer.py] => FB_epoch_inc: 31
2026-01-16 00:55:34,938 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 00:55:34,939 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 00:55:34,939 [trainer.py] => pool: 10
2026-01-16 00:55:34,939 [trainer.py] => sg_num: 1
2026-01-16 00:55:34,939 [trainer.py] => gamma: 0.1
2026-01-16 00:55:34,939 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 00:55:34,939 [trainer.py] => prefix: continual-CLIP-INR
2026-01-16 00:55:34,939 [trainer.py] => model_name: combined_learner
2026-01-16 00:55:34,939 [trainer.py] => model_size: ViT-B/16
2026-01-16 00:55:34,939 [trainer.py] => convnet_type: none
2026-01-16 00:55:34,939 [trainer.py] => seed: 1993
2026-01-16 00:55:34,940 [trainer.py] => batch_size: 64
2026-01-16 00:55:34,940 [trainer.py] => num_workers: 8
2026-01-16 00:55:34,941 [trainer.py] => model_type: clip
2026-01-16 00:55:34,941 [trainer.py] => division_power: 5
2026-01-16 00:55:34,941 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 00:55:34,941 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 00:55:34,941 [trainer.py] => regularizer: mahalanobis
2026-01-16 00:55:34,941 [trainer.py] => print_freq: 10
2026-01-16 00:55:34,942 [trainer.py] => memory_size: 0
2026-01-16 00:55:34,942 [trainer.py] => k: 10
2026-01-16 00:55:34,942 [trainer.py] => sim_coeff: 1.0
2026-01-16 00:55:34,942 [trainer.py] => sparse_coeff: 0.001
2026-01-16 00:55:34,942 [trainer.py] => repeat: False
2026-01-16 00:55:34,942 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 00:55:34,942 [trainer.py] => num_archetypes: 4
2026-01-16 00:55:34,942 [trainer.py] => augment: 0
2026-01-16 01:31:20,858 [trainer.py] => config: exps/10,10_imagenet-r.json
2026-01-16 01:31:20,858 [trainer.py] => dataset: imagenet-r
2026-01-16 01:31:20,859 [trainer.py] => shuffle: True
2026-01-16 01:31:20,859 [trainer.py] => init_cls: 10
2026-01-16 01:31:20,859 [trainer.py] => increment: 10
2026-01-16 01:31:20,859 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 01:31:20,863 [trainer.py] => sim: 1
2026-01-16 01:31:20,864 [trainer.py] => epochs: 31
2026-01-16 01:31:20,864 [trainer.py] => lr: 0.01
2026-01-16 01:31:20,864 [trainer.py] => FB_epoch: 51
2026-01-16 01:31:20,868 [trainer.py] => FB_epoch_inc: 31
2026-01-16 01:31:20,868 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 01:31:20,868 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 01:31:20,868 [trainer.py] => pool: 10
2026-01-16 01:31:20,869 [trainer.py] => sg_num: 1
2026-01-16 01:31:20,869 [trainer.py] => gamma: 0.1
2026-01-16 01:31:20,869 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 01:31:20,869 [trainer.py] => prefix: continual-CLIP-INR
2026-01-16 01:31:20,869 [trainer.py] => model_name: combined_learner
2026-01-16 01:31:20,869 [trainer.py] => model_size: ViT-B/16
2026-01-16 01:31:20,869 [trainer.py] => convnet_type: none
2026-01-16 01:31:20,869 [trainer.py] => seed: 1993
2026-01-16 01:31:20,869 [trainer.py] => batch_size: 64
2026-01-16 01:31:20,869 [trainer.py] => num_workers: 8
2026-01-16 01:31:20,869 [trainer.py] => model_type: clip
2026-01-16 01:31:20,870 [trainer.py] => division_power: 5
2026-01-16 01:31:20,870 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 01:31:20,870 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 01:31:20,870 [trainer.py] => regularizer: mahalanobis
2026-01-16 01:31:20,870 [trainer.py] => print_freq: 10
2026-01-16 01:31:20,870 [trainer.py] => memory_size: 0
2026-01-16 01:31:20,870 [trainer.py] => k: 10
2026-01-16 01:31:20,870 [trainer.py] => sim_coeff: 1.0
2026-01-16 01:31:20,870 [trainer.py] => sparse_coeff: 0.001
2026-01-16 01:31:20,871 [trainer.py] => repeat: False
2026-01-16 01:31:20,871 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 01:31:20,871 [trainer.py] => num_archetypes: 4
2026-01-16 01:31:20,871 [trainer.py] => augment: 0
2026-01-16 01:33:05,475 [trainer.py] => config: exps/10,10_imagenet-r.json
2026-01-16 01:33:05,475 [trainer.py] => dataset: imagenet-r
2026-01-16 01:33:05,476 [trainer.py] => shuffle: True
2026-01-16 01:33:05,478 [trainer.py] => init_cls: 10
2026-01-16 01:33:05,478 [trainer.py] => increment: 10
2026-01-16 01:33:05,478 [trainer.py] => device: [device(type='cuda', index=0)]
2026-01-16 01:33:05,479 [trainer.py] => sim: 1
2026-01-16 01:33:05,479 [trainer.py] => epochs: 31
2026-01-16 01:33:05,479 [trainer.py] => lr: 0.01
2026-01-16 01:33:05,479 [trainer.py] => FB_epoch: 51
2026-01-16 01:33:05,479 [trainer.py] => FB_epoch_inc: 31
2026-01-16 01:33:05,482 [trainer.py] => FB_lr_init: 0.0008
2026-01-16 01:33:05,483 [trainer.py] => FB_lr_inc: 0.0008
2026-01-16 01:33:05,483 [trainer.py] => pool: 10
2026-01-16 01:33:05,484 [trainer.py] => sg_num: 1
2026-01-16 01:33:05,484 [trainer.py] => gamma: 0.1
2026-01-16 01:33:05,484 [trainer.py] => milestones: [30, 40, 50]
2026-01-16 01:33:05,484 [trainer.py] => prefix: continual-CLIP-INR
2026-01-16 01:33:05,489 [trainer.py] => model_name: combined_learner
2026-01-16 01:33:05,490 [trainer.py] => model_size: ViT-B/16
2026-01-16 01:33:05,490 [trainer.py] => convnet_type: none
2026-01-16 01:33:05,490 [trainer.py] => seed: 1993
2026-01-16 01:33:05,490 [trainer.py] => batch_size: 64
2026-01-16 01:33:05,491 [trainer.py] => num_workers: 8
2026-01-16 01:33:05,491 [trainer.py] => model_type: clip
2026-01-16 01:33:05,491 [trainer.py] => division_power: 5
2026-01-16 01:33:05,491 [trainer.py] => linear_model: ['linear', 'bn', 'linear']
2026-01-16 01:33:05,492 [trainer.py] => score_model: ['bn', 'linear']
2026-01-16 01:33:05,492 [trainer.py] => regularizer: mahalanobis
2026-01-16 01:33:05,492 [trainer.py] => print_freq: 10
2026-01-16 01:33:05,492 [trainer.py] => memory_size: 0
2026-01-16 01:33:05,492 [trainer.py] => k: 10
2026-01-16 01:33:05,492 [trainer.py] => sim_coeff: 1.0
2026-01-16 01:33:05,492 [trainer.py] => sparse_coeff: 0.001
2026-01-16 01:33:05,492 [trainer.py] => repeat: False
2026-01-16 01:33:05,493 [trainer.py] => interpolation_ratio: 0.3
2026-01-16 01:33:05,493 [trainer.py] => num_archetypes: 4
2026-01-16 01:33:05,493 [trainer.py] => augment: 0
2026-01-16 01:33:07,336 [data_manager.py] => [168, 136, 51, 9, 183, 101, 171, 99, 42, 159, 191, 70, 16, 188, 27, 10, 175, 26, 68, 187, 98, 6, 85, 35, 112, 43, 100, 0, 103, 181, 88, 59, 4, 2, 116, 174, 94, 80, 106, 1, 147, 17, 141, 131, 72, 23, 173, 54, 197, 118, 87, 32, 79, 104, 91, 19, 135, 107, 178, 36, 11, 199, 142, 8, 122, 3, 28, 57, 153, 172, 190, 56, 49, 44, 97, 62, 151, 169, 194, 55, 192, 12, 189, 78, 66, 180, 15, 137, 109, 134, 92, 119, 126, 52, 170, 40, 148, 65, 144, 64, 138, 45, 77, 89, 154, 90, 71, 193, 74, 30, 113, 143, 96, 84, 67, 50, 186, 156, 69, 21, 18, 111, 108, 58, 125, 157, 150, 110, 182, 129, 166, 83, 81, 60, 13, 165, 14, 176, 63, 117, 5, 22, 145, 121, 38, 41, 82, 127, 114, 20, 31, 53, 37, 163, 196, 130, 152, 162, 86, 76, 24, 34, 184, 149, 33, 128, 198, 155, 146, 167, 139, 120, 140, 102, 47, 25, 158, 123, 46, 164, 61, 7, 115, 75, 133, 160, 105, 132, 179, 124, 48, 73, 93, 39, 95, 195, 29, 177, 185, 161]
2026-01-16 01:33:07,415 [SGC.py] => Learning on task 0 (10 new classes): 0-9
2026-01-16 01:33:07,416 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 01:33:57,906 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 01:34:22,568 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 01:34:22,568 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 01:34:22,575 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9]}
2026-01-16 01:34:22,577 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 01:34:51,892 [SGC.py] => Starting model training. Training ALL 2 groups.
2026-01-16 01:34:51,897 [SGC.py] => Unfreezing components for ALL groups: [1, 2]
2026-01-16 01:35:52,361 [SGC.py] => Task: 0, Epoch: 1, Train Loss: 2.234362, Train Acc: 56.9087, Test Acc on New: 68.6154
2026-01-16 01:35:52,415 [SGC.py] => New best accuracy found: 68.62%
2026-01-16 01:37:53,228 [SGC.py] => Task: 0, Epoch: 11, Train Loss: 0.473706, Train Acc: 95.5504, Test Acc on New: 92.6154
2026-01-16 01:37:53,250 [SGC.py] => New best accuracy found: 92.62%
2026-01-16 01:40:40,551 [SGC.py] => Task: 0, Epoch: 21, Train Loss: 0.157344, Train Acc: 98.3607, Test Acc on New: 95.3846
2026-01-16 01:40:40,603 [SGC.py] => New best accuracy found: 95.38%
2026-01-16 01:44:39,975 [SGC.py] => Task: 0, Epoch: 31, Train Loss: 0.103899, Train Acc: 98.8290, Test Acc on New: 96.0000
2026-01-16 01:44:40,023 [SGC.py] => New best accuracy found: 96.00%
2026-01-16 01:47:38,319 [SGC.py] => Task: 0, Epoch: 41, Train Loss: 0.088954, Train Acc: 98.9852, Test Acc on New: 96.0000
2026-01-16 01:50:48,760 [SGC.py] => Task: 0, Epoch: 51, Train Loss: 0.088941, Train Acc: 98.9852, Test Acc on New: 96.0000
2026-01-16 01:50:48,760 [SGC.py] => Loading best model for task 0 with Test Acc on New: 96.00%
2026-01-16 01:51:21,944 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 01:51:21,945 [SGC.py] => CNN accuracy: {'total': np.float64(96.0), 'group_1': np.float64(98.22), 'group_2': np.float64(93.59), 'old': 0, 'new': np.float64(96.0), 'top1': np.float64(96.0), 'top5': np.float64(99.38), 'grouped': {'total': np.float64(96.0), 'group_1': np.float64(98.22), 'group_2': np.float64(93.59), 'old': 0, 'new': np.float64(96.0), 'top1': np.float64(96.0), 'top5': np.float64(99.38)}}
2026-01-16 01:51:21,945 [trainer.py] => No NME accuracy.
2026-01-16 01:51:21,945 [trainer.py] => CNN: {'total': np.float64(96.0), 'group_1': np.float64(98.22), 'group_2': np.float64(93.59), 'old': 0, 'new': np.float64(96.0), 'top1': np.float64(96.0), 'top5': np.float64(99.38)}
2026-01-16 01:51:21,945 [trainer.py] => CNN top1 curve: [np.float64(96.0)]
2026-01-16 01:51:21,946 [trainer.py] => CNN top5 curve: [np.float64(99.38)]

2026-01-16 01:51:21,946 [trainer.py] => Average Accuracy (CNN): 96.0
2026-01-16 01:51:21,947 [SGC.py] => Learning on task 1 (10 new classes): 10-19
2026-01-16 01:51:21,948 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 01:52:03,627 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 01:52:27,420 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 01:52:27,421 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 01:52:27,423 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18]}
2026-01-16 01:52:27,440 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 01:52:53,203 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 01:52:53,354 [SGC.py] => Starting model training. Training ALL 4 groups.
2026-01-16 01:52:53,356 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4]
2026-01-16 01:53:54,779 [SGC.py] => Task: 1, Epoch: 1, Train Loss: 1.539788, Train Acc: 53.3419, Test Acc on New: 26.8930
2026-01-16 01:53:54,834 [SGC.py] => New best accuracy found: 26.89%
2026-01-16 01:56:30,900 [SGC.py] => Task: 1, Epoch: 11, Train Loss: 0.115318, Train Acc: 98.5793, Test Acc on New: 94.5170
2026-01-16 01:56:30,915 [SGC.py] => New best accuracy found: 94.52%
2026-01-16 01:59:28,664 [SGC.py] => Task: 1, Epoch: 21, Train Loss: 0.046231, Train Acc: 99.8386, Test Acc on New: 95.5614
2026-01-16 01:59:28,721 [SGC.py] => New best accuracy found: 95.56%
2026-01-16 02:02:11,856 [SGC.py] => Task: 1, Epoch: 31, Train Loss: 0.026340, Train Acc: 100.0000, Test Acc on New: 95.8225
2026-01-16 02:02:11,875 [SGC.py] => New best accuracy found: 95.82%
2026-01-16 02:02:11,875 [SGC.py] => Loading best model for task 1 with Test Acc on New: 95.82%
2026-01-16 02:02:52,354 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 02:02:52,355 [SGC.py] => CNN accuracy: {'total': np.float64(95.34), 'group_1': np.float64(96.45), 'group_2': np.float64(92.95), 'group_3': np.float64(96.57), 'group_4': np.float64(94.97), 'old': np.float64(94.77), 'new': np.float64(95.82), 'top1': np.float64(95.34), 'top5': np.float64(99.01), 'grouped': {'total': np.float64(95.34), 'group_1': np.float64(96.45), 'group_2': np.float64(92.95), 'group_3': np.float64(96.57), 'group_4': np.float64(94.97), 'old': np.float64(94.77), 'new': np.float64(95.82), 'top1': np.float64(95.34), 'top5': np.float64(99.01)}}
2026-01-16 02:02:52,355 [trainer.py] => No NME accuracy.
2026-01-16 02:02:52,356 [trainer.py] => CNN: {'total': np.float64(95.34), 'group_1': np.float64(96.45), 'group_2': np.float64(92.95), 'group_3': np.float64(96.57), 'group_4': np.float64(94.97), 'old': np.float64(94.77), 'new': np.float64(95.82), 'top1': np.float64(95.34), 'top5': np.float64(99.01)}
2026-01-16 02:02:52,356 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34)]
2026-01-16 02:02:52,356 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01)]

2026-01-16 02:02:52,356 [trainer.py] => Average Accuracy (CNN): 95.67
2026-01-16 02:02:52,356 [SGC.py] => Learning on task 2 (10 new classes): 20-29
2026-01-16 02:02:52,358 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 02:03:30,096 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 02:03:45,137 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 02:03:45,137 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 02:03:45,138 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27]}
2026-01-16 02:03:45,146 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 02:04:00,203 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 02:04:00,256 [SGC.py] => Starting model training. Training ALL 6 groups.
2026-01-16 02:04:00,257 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6]
2026-01-16 02:04:44,249 [SGC.py] => Task: 2, Epoch: 1, Train Loss: 1.530592, Train Acc: 66.9698, Test Acc on New: 1.9417
2026-01-16 02:04:44,276 [SGC.py] => New best accuracy found: 1.94%
2026-01-16 02:07:02,920 [SGC.py] => Task: 2, Epoch: 11, Train Loss: 0.097866, Train Acc: 98.9302, Test Acc on New: 92.5566
2026-01-16 02:07:02,968 [SGC.py] => New best accuracy found: 92.56%
2026-01-16 02:09:36,095 [SGC.py] => Task: 2, Epoch: 21, Train Loss: 0.045293, Train Acc: 99.7860, Test Acc on New: 93.2039
2026-01-16 02:09:36,118 [SGC.py] => New best accuracy found: 93.20%
2026-01-16 02:12:29,904 [SGC.py] => Task: 2, Epoch: 31, Train Loss: 0.029058, Train Acc: 99.9733, Test Acc on New: 93.5275
2026-01-16 02:12:29,953 [SGC.py] => New best accuracy found: 93.53%
2026-01-16 02:12:29,954 [SGC.py] => Loading best model for task 2 with Test Acc on New: 93.53%
2026-01-16 02:13:16,800 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 02:13:16,801 [SGC.py] => CNN accuracy: {'total': np.float64(92.53), 'group_1': np.float64(94.67), 'group_2': np.float64(88.46), 'group_3': np.float64(93.14), 'group_4': np.float64(91.62), 'group_5': np.float64(97.67), 'group_6': np.float64(88.32), 'old': np.float64(92.09), 'new': np.float64(93.53), 'top1': np.float64(92.53), 'top5': np.float64(98.03), 'grouped': {'total': np.float64(92.53), 'group_1': np.float64(94.67), 'group_2': np.float64(88.46), 'group_3': np.float64(93.14), 'group_4': np.float64(91.62), 'group_5': np.float64(97.67), 'group_6': np.float64(88.32), 'old': np.float64(92.09), 'new': np.float64(93.53), 'top1': np.float64(92.53), 'top5': np.float64(98.03)}}
2026-01-16 02:13:16,801 [trainer.py] => No NME accuracy.
2026-01-16 02:13:16,801 [trainer.py] => CNN: {'total': np.float64(92.53), 'group_1': np.float64(94.67), 'group_2': np.float64(88.46), 'group_3': np.float64(93.14), 'group_4': np.float64(91.62), 'group_5': np.float64(97.67), 'group_6': np.float64(88.32), 'old': np.float64(92.09), 'new': np.float64(93.53), 'top1': np.float64(92.53), 'top5': np.float64(98.03)}
2026-01-16 02:13:16,801 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53)]
2026-01-16 02:13:16,802 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03)]

2026-01-16 02:13:16,802 [trainer.py] => Average Accuracy (CNN): 94.62333333333333
2026-01-16 02:13:16,802 [SGC.py] => Learning on task 3 (10 new classes): 30-39
2026-01-16 02:13:16,803 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 02:13:51,424 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 02:14:16,327 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 02:14:16,327 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 02:14:16,330 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39]}
2026-01-16 02:14:16,353 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 02:14:41,408 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 02:14:41,531 [SGC.py] => Starting model training. Training ALL 8 groups.
2026-01-16 02:14:41,533 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8]
2026-01-16 02:15:43,514 [SGC.py] => Task: 3, Epoch: 1, Train Loss: 1.200886, Train Acc: 75.0411, Test Acc on New: 7.3964
2026-01-16 02:15:43,565 [SGC.py] => New best accuracy found: 7.40%
2026-01-16 02:19:31,629 [SGC.py] => Task: 3, Epoch: 11, Train Loss: 0.089371, Train Acc: 98.9600, Test Acc on New: 91.7160
2026-01-16 02:19:31,690 [SGC.py] => New best accuracy found: 91.72%
2026-01-16 02:23:19,434 [SGC.py] => Task: 3, Epoch: 21, Train Loss: 0.052241, Train Acc: 99.5986, Test Acc on New: 92.6036
2026-01-16 02:23:19,478 [SGC.py] => New best accuracy found: 92.60%
2026-01-16 02:27:06,221 [SGC.py] => Task: 3, Epoch: 31, Train Loss: 0.036500, Train Acc: 99.8540, Test Acc on New: 92.3077
2026-01-16 02:27:06,221 [SGC.py] => Loading best model for task 3 with Test Acc on New: 92.60%
2026-01-16 02:27:53,457 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 02:27:53,459 [SGC.py] => CNN accuracy: {'total': np.float64(91.29), 'group_1': np.float64(94.67), 'group_2': np.float64(89.1), 'group_3': np.float64(92.65), 'group_4': np.float64(87.71), 'group_5': np.float64(94.19), 'group_6': np.float64(85.4), 'group_7': np.float64(95.3), 'group_8': np.float64(90.48), 'old': np.float64(90.86), 'new': np.float64(92.6), 'top1': np.float64(91.29), 'top5': np.float64(97.71), 'grouped': {'total': np.float64(91.29), 'group_1': np.float64(94.67), 'group_2': np.float64(89.1), 'group_3': np.float64(92.65), 'group_4': np.float64(87.71), 'group_5': np.float64(94.19), 'group_6': np.float64(85.4), 'group_7': np.float64(95.3), 'group_8': np.float64(90.48), 'old': np.float64(90.86), 'new': np.float64(92.6), 'top1': np.float64(91.29), 'top5': np.float64(97.71)}}
2026-01-16 02:27:53,459 [trainer.py] => No NME accuracy.
2026-01-16 02:27:53,459 [trainer.py] => CNN: {'total': np.float64(91.29), 'group_1': np.float64(94.67), 'group_2': np.float64(89.1), 'group_3': np.float64(92.65), 'group_4': np.float64(87.71), 'group_5': np.float64(94.19), 'group_6': np.float64(85.4), 'group_7': np.float64(95.3), 'group_8': np.float64(90.48), 'old': np.float64(90.86), 'new': np.float64(92.6), 'top1': np.float64(91.29), 'top5': np.float64(97.71)}
2026-01-16 02:27:53,459 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29)]
2026-01-16 02:27:53,459 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71)]

2026-01-16 02:27:53,460 [trainer.py] => Average Accuracy (CNN): 93.79
2026-01-16 02:27:53,460 [SGC.py] => Learning on task 4 (10 new classes): 40-49
2026-01-16 02:27:53,461 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 02:28:39,867 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 02:29:04,247 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 02:29:04,248 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 02:29:04,251 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49]}
2026-01-16 02:29:04,272 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 02:29:29,069 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 02:29:29,218 [SGC.py] => Starting model training. Training ALL 10 groups.
2026-01-16 02:29:29,220 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]
2026-01-16 02:30:31,926 [SGC.py] => Task: 4, Epoch: 1, Train Loss: 0.932780, Train Acc: 79.8925, Test Acc on New: 16.2544
2026-01-16 02:30:31,979 [SGC.py] => New best accuracy found: 16.25%
2026-01-16 02:34:27,273 [SGC.py] => Task: 4, Epoch: 11, Train Loss: 0.063007, Train Acc: 99.6013, Test Acc on New: 93.9929
2026-01-16 02:34:27,328 [SGC.py] => New best accuracy found: 93.99%
2026-01-16 02:38:23,653 [SGC.py] => Task: 4, Epoch: 21, Train Loss: 0.038458, Train Acc: 99.9133, Test Acc on New: 94.6996
2026-01-16 02:38:23,699 [SGC.py] => New best accuracy found: 94.70%
2026-01-16 02:42:20,682 [SGC.py] => Task: 4, Epoch: 31, Train Loss: 0.031596, Train Acc: 99.9653, Test Acc on New: 93.6396
2026-01-16 02:42:20,683 [SGC.py] => Loading best model for task 4 with Test Acc on New: 94.70%
2026-01-16 02:43:08,419 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 02:43:08,421 [SGC.py] => CNN accuracy: {'total': np.float64(90.54), 'group_1': np.float64(94.08), 'group_2': np.float64(85.9), 'group_3': np.float64(90.69), 'group_4': np.float64(87.71), 'group_5': np.float64(93.02), 'group_6': np.float64(83.94), 'group_7': np.float64(91.95), 'group_8': np.float64(88.89), 'group_9': np.float64(95.42), 'group_10': np.float64(94.08), 'old': np.float64(89.67), 'new': np.float64(94.7), 'top1': np.float64(90.54), 'top5': np.float64(97.44), 'grouped': {'total': np.float64(90.54), 'group_1': np.float64(94.08), 'group_2': np.float64(85.9), 'group_3': np.float64(90.69), 'group_4': np.float64(87.71), 'group_5': np.float64(93.02), 'group_6': np.float64(83.94), 'group_7': np.float64(91.95), 'group_8': np.float64(88.89), 'group_9': np.float64(95.42), 'group_10': np.float64(94.08), 'old': np.float64(89.67), 'new': np.float64(94.7), 'top1': np.float64(90.54), 'top5': np.float64(97.44)}}
2026-01-16 02:43:08,421 [trainer.py] => No NME accuracy.
2026-01-16 02:43:08,421 [trainer.py] => CNN: {'total': np.float64(90.54), 'group_1': np.float64(94.08), 'group_2': np.float64(85.9), 'group_3': np.float64(90.69), 'group_4': np.float64(87.71), 'group_5': np.float64(93.02), 'group_6': np.float64(83.94), 'group_7': np.float64(91.95), 'group_8': np.float64(88.89), 'group_9': np.float64(95.42), 'group_10': np.float64(94.08), 'old': np.float64(89.67), 'new': np.float64(94.7), 'top1': np.float64(90.54), 'top5': np.float64(97.44)}
2026-01-16 02:43:08,421 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54)]
2026-01-16 02:43:08,422 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44)]

2026-01-16 02:43:08,431 [trainer.py] => Average Accuracy (CNN): 93.14000000000001
2026-01-16 02:43:08,438 [SGC.py] => Learning on task 5 (10 new classes): 50-59
2026-01-16 02:43:08,441 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 02:43:55,634 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 02:44:20,569 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 02:44:20,569 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 02:44:20,572 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59]}
2026-01-16 02:44:20,596 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 02:44:46,026 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 02:44:46,223 [SGC.py] => Starting model training. Training ALL 12 groups.
2026-01-16 02:44:46,225 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]
2026-01-16 02:45:52,063 [SGC.py] => Task: 5, Epoch: 1, Train Loss: 0.928697, Train Acc: 82.7817, Test Acc on New: 19.8083
2026-01-16 02:45:52,115 [SGC.py] => New best accuracy found: 19.81%
2026-01-16 02:50:13,230 [SGC.py] => Task: 5, Epoch: 11, Train Loss: 0.078089, Train Acc: 99.3696, Test Acc on New: 90.7348
2026-01-16 02:50:13,283 [SGC.py] => New best accuracy found: 90.73%
2026-01-16 02:54:35,280 [SGC.py] => Task: 5, Epoch: 21, Train Loss: 0.049423, Train Acc: 99.8687, Test Acc on New: 92.0128
2026-01-16 02:54:35,328 [SGC.py] => New best accuracy found: 92.01%
2026-01-16 02:58:58,634 [SGC.py] => Task: 5, Epoch: 31, Train Loss: 0.039734, Train Acc: 99.9212, Test Acc on New: 91.3738
2026-01-16 02:58:58,634 [SGC.py] => Loading best model for task 5 with Test Acc on New: 92.01%
2026-01-16 02:59:47,080 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 02:59:47,082 [SGC.py] => CNN accuracy: {'total': np.float64(89.65), 'group_1': np.float64(95.27), 'group_2': np.float64(86.54), 'group_3': np.float64(90.2), 'group_4': np.float64(85.47), 'group_5': np.float64(87.79), 'group_6': np.float64(83.94), 'group_7': np.float64(86.58), 'group_8': np.float64(91.01), 'group_9': np.float64(94.66), 'group_10': np.float64(90.13), 'group_11': np.float64(91.16), 'group_12': np.float64(92.77), 'old': np.float64(89.19), 'new': np.float64(92.01), 'top1': np.float64(89.65), 'top5': np.float64(97.33), 'grouped': {'total': np.float64(89.65), 'group_1': np.float64(95.27), 'group_2': np.float64(86.54), 'group_3': np.float64(90.2), 'group_4': np.float64(85.47), 'group_5': np.float64(87.79), 'group_6': np.float64(83.94), 'group_7': np.float64(86.58), 'group_8': np.float64(91.01), 'group_9': np.float64(94.66), 'group_10': np.float64(90.13), 'group_11': np.float64(91.16), 'group_12': np.float64(92.77), 'old': np.float64(89.19), 'new': np.float64(92.01), 'top1': np.float64(89.65), 'top5': np.float64(97.33)}}
2026-01-16 02:59:47,082 [trainer.py] => No NME accuracy.
2026-01-16 02:59:47,082 [trainer.py] => CNN: {'total': np.float64(89.65), 'group_1': np.float64(95.27), 'group_2': np.float64(86.54), 'group_3': np.float64(90.2), 'group_4': np.float64(85.47), 'group_5': np.float64(87.79), 'group_6': np.float64(83.94), 'group_7': np.float64(86.58), 'group_8': np.float64(91.01), 'group_9': np.float64(94.66), 'group_10': np.float64(90.13), 'group_11': np.float64(91.16), 'group_12': np.float64(92.77), 'old': np.float64(89.19), 'new': np.float64(92.01), 'top1': np.float64(89.65), 'top5': np.float64(97.33)}
2026-01-16 02:59:47,082 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65)]
2026-01-16 02:59:47,083 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33)]

2026-01-16 02:59:47,085 [trainer.py] => Average Accuracy (CNN): 92.55833333333334
2026-01-16 02:59:47,088 [SGC.py] => Learning on task 6 (10 new classes): 60-69
2026-01-16 02:59:47,095 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 03:00:33,402 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 03:00:58,106 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 03:00:58,106 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 03:00:58,109 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68]}
2026-01-16 03:00:58,134 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 03:01:23,199 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 03:01:23,414 [SGC.py] => Starting model training. Training ALL 14 groups.
2026-01-16 03:01:23,416 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]
2026-01-16 03:02:30,018 [SGC.py] => Task: 6, Epoch: 1, Train Loss: 0.775484, Train Acc: 85.2965, Test Acc on New: 25.6579
2026-01-16 03:02:30,063 [SGC.py] => New best accuracy found: 25.66%
2026-01-16 03:07:07,218 [SGC.py] => Task: 6, Epoch: 11, Train Loss: 0.079716, Train Acc: 99.4567, Test Acc on New: 88.1579
2026-01-16 03:07:07,279 [SGC.py] => New best accuracy found: 88.16%
2026-01-16 03:11:46,024 [SGC.py] => Task: 6, Epoch: 21, Train Loss: 0.053678, Train Acc: 99.8151, Test Acc on New: 86.5132
2026-01-16 03:16:25,006 [SGC.py] => Task: 6, Epoch: 31, Train Loss: 0.047692, Train Acc: 99.9538, Test Acc on New: 87.5000
2026-01-16 03:16:25,007 [SGC.py] => Loading best model for task 6 with Test Acc on New: 88.16%
2026-01-16 03:17:14,275 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 03:17:14,277 [SGC.py] => CNN accuracy: {'total': np.float64(87.54), 'group_1': np.float64(89.94), 'group_2': np.float64(83.97), 'group_3': np.float64(89.22), 'group_4': np.float64(83.24), 'group_5': np.float64(88.95), 'group_6': np.float64(83.21), 'group_7': np.float64(85.91), 'group_8': np.float64(89.42), 'group_9': np.float64(95.42), 'group_10': np.float64(87.5), 'group_11': np.float64(85.71), 'group_12': np.float64(86.75), 'group_13': np.float64(90.24), 'group_14': np.float64(85.71), 'old': np.float64(87.44), 'new': np.float64(88.16), 'top1': np.float64(87.54), 'top5': np.float64(96.36), 'grouped': {'total': np.float64(87.54), 'group_1': np.float64(89.94), 'group_2': np.float64(83.97), 'group_3': np.float64(89.22), 'group_4': np.float64(83.24), 'group_5': np.float64(88.95), 'group_6': np.float64(83.21), 'group_7': np.float64(85.91), 'group_8': np.float64(89.42), 'group_9': np.float64(95.42), 'group_10': np.float64(87.5), 'group_11': np.float64(85.71), 'group_12': np.float64(86.75), 'group_13': np.float64(90.24), 'group_14': np.float64(85.71), 'old': np.float64(87.44), 'new': np.float64(88.16), 'top1': np.float64(87.54), 'top5': np.float64(96.36)}}
2026-01-16 03:17:14,277 [trainer.py] => No NME accuracy.
2026-01-16 03:17:14,277 [trainer.py] => CNN: {'total': np.float64(87.54), 'group_1': np.float64(89.94), 'group_2': np.float64(83.97), 'group_3': np.float64(89.22), 'group_4': np.float64(83.24), 'group_5': np.float64(88.95), 'group_6': np.float64(83.21), 'group_7': np.float64(85.91), 'group_8': np.float64(89.42), 'group_9': np.float64(95.42), 'group_10': np.float64(87.5), 'group_11': np.float64(85.71), 'group_12': np.float64(86.75), 'group_13': np.float64(90.24), 'group_14': np.float64(85.71), 'old': np.float64(87.44), 'new': np.float64(88.16), 'top1': np.float64(87.54), 'top5': np.float64(96.36)}
2026-01-16 03:17:14,277 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54)]
2026-01-16 03:17:14,277 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36)]

2026-01-16 03:17:14,283 [trainer.py] => Average Accuracy (CNN): 91.84142857142857
2026-01-16 03:17:14,288 [SGC.py] => Learning on task 7 (10 new classes): 70-79
2026-01-16 03:17:14,296 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 03:18:00,495 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 03:18:24,709 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 03:18:24,710 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 03:18:24,712 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78]}
2026-01-16 03:18:24,748 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 03:18:48,914 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 03:18:49,152 [SGC.py] => Starting model training. Training ALL 16 groups.
2026-01-16 03:18:49,154 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]
2026-01-16 03:19:58,139 [SGC.py] => Task: 7, Epoch: 1, Train Loss: 0.668508, Train Acc: 86.7160, Test Acc on New: 39.2727
2026-01-16 03:19:58,193 [SGC.py] => New best accuracy found: 39.27%
2026-01-16 03:25:01,429 [SGC.py] => Task: 7, Epoch: 11, Train Loss: 0.083648, Train Acc: 99.5624, Test Acc on New: 88.3636
2026-01-16 03:25:01,475 [SGC.py] => New best accuracy found: 88.36%
2026-01-16 03:30:20,745 [SGC.py] => Task: 7, Epoch: 21, Train Loss: 0.056994, Train Acc: 99.9215, Test Acc on New: 89.4545
2026-01-16 03:30:20,821 [SGC.py] => New best accuracy found: 89.45%
2026-01-16 03:35:15,022 [SGC.py] => Task: 7, Epoch: 31, Train Loss: 0.048948, Train Acc: 99.9215, Test Acc on New: 89.0909
2026-01-16 03:35:15,023 [SGC.py] => Loading best model for task 7 with Test Acc on New: 89.45%
2026-01-16 03:36:05,050 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 03:36:05,052 [SGC.py] => CNN accuracy: {'total': np.float64(86.56), 'group_1': np.float64(89.35), 'group_2': np.float64(84.62), 'group_3': np.float64(88.24), 'group_4': np.float64(84.36), 'group_5': np.float64(88.95), 'group_6': np.float64(84.67), 'group_7': np.float64(85.23), 'group_8': np.float64(87.83), 'group_9': np.float64(93.89), 'group_10': np.float64(81.58), 'group_11': np.float64(85.03), 'group_12': np.float64(87.95), 'group_13': np.float64(85.37), 'group_14': np.float64(78.57), 'group_15': np.float64(88.97), 'group_16': np.float64(89.93), 'old': np.float64(86.21), 'new': np.float64(89.45), 'top1': np.float64(86.56), 'top5': np.float64(96.56), 'grouped': {'total': np.float64(86.56), 'group_1': np.float64(89.35), 'group_2': np.float64(84.62), 'group_3': np.float64(88.24), 'group_4': np.float64(84.36), 'group_5': np.float64(88.95), 'group_6': np.float64(84.67), 'group_7': np.float64(85.23), 'group_8': np.float64(87.83), 'group_9': np.float64(93.89), 'group_10': np.float64(81.58), 'group_11': np.float64(85.03), 'group_12': np.float64(87.95), 'group_13': np.float64(85.37), 'group_14': np.float64(78.57), 'group_15': np.float64(88.97), 'group_16': np.float64(89.93), 'old': np.float64(86.21), 'new': np.float64(89.45), 'top1': np.float64(86.56), 'top5': np.float64(96.56)}}
2026-01-16 03:36:05,053 [trainer.py] => No NME accuracy.
2026-01-16 03:36:05,053 [trainer.py] => CNN: {'total': np.float64(86.56), 'group_1': np.float64(89.35), 'group_2': np.float64(84.62), 'group_3': np.float64(88.24), 'group_4': np.float64(84.36), 'group_5': np.float64(88.95), 'group_6': np.float64(84.67), 'group_7': np.float64(85.23), 'group_8': np.float64(87.83), 'group_9': np.float64(93.89), 'group_10': np.float64(81.58), 'group_11': np.float64(85.03), 'group_12': np.float64(87.95), 'group_13': np.float64(85.37), 'group_14': np.float64(78.57), 'group_15': np.float64(88.97), 'group_16': np.float64(89.93), 'old': np.float64(86.21), 'new': np.float64(89.45), 'top1': np.float64(86.56), 'top5': np.float64(96.56)}
2026-01-16 03:36:05,056 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56)]
2026-01-16 03:36:05,063 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56)]

2026-01-16 03:36:05,071 [trainer.py] => Average Accuracy (CNN): 91.18125
2026-01-16 03:36:05,071 [SGC.py] => Learning on task 8 (10 new classes): 80-89
2026-01-16 03:36:05,074 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 03:36:52,051 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 03:37:16,635 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 03:37:16,636 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 03:37:16,640 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87]}
2026-01-16 03:37:16,673 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 03:37:41,576 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 03:37:41,848 [SGC.py] => Starting model training. Training ALL 18 groups.
2026-01-16 03:37:41,850 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]
2026-01-16 03:38:56,200 [SGC.py] => Task: 8, Epoch: 1, Train Loss: 0.593529, Train Acc: 88.6553, Test Acc on New: 48.5714
2026-01-16 03:38:56,254 [SGC.py] => New best accuracy found: 48.57%
2026-01-16 06:56:01,243 [SGC.py] => Task: 8, Epoch: 11, Train Loss: 0.073738, Train Acc: 99.7874, Test Acc on New: 88.5714
2026-01-16 06:56:01,681 [SGC.py] => New best accuracy found: 88.57%
2026-01-16 07:02:01,456 [SGC.py] => Task: 8, Epoch: 21, Train Loss: 0.054382, Train Acc: 99.9055, Test Acc on New: 90.2857
2026-01-16 07:02:01,513 [SGC.py] => New best accuracy found: 90.29%
2026-01-16 07:07:59,716 [SGC.py] => Task: 8, Epoch: 31, Train Loss: 0.047375, Train Acc: 99.9213, Test Acc on New: 89.4286
2026-01-16 07:07:59,716 [SGC.py] => Loading best model for task 8 with Test Acc on New: 90.29%
2026-01-16 07:08:50,637 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 07:08:50,639 [SGC.py] => CNN accuracy: {'total': np.float64(86.18), 'group_1': np.float64(91.12), 'group_2': np.float64(84.62), 'group_3': np.float64(83.82), 'group_4': np.float64(84.36), 'group_5': np.float64(86.63), 'group_6': np.float64(84.67), 'group_7': np.float64(85.91), 'group_8': np.float64(84.66), 'group_9': np.float64(93.13), 'group_10': np.float64(84.87), 'group_11': np.float64(85.71), 'group_12': np.float64(88.55), 'group_13': np.float64(85.98), 'group_14': np.float64(73.57), 'group_15': np.float64(83.09), 'group_16': np.float64(89.21), 'group_17': np.float64(90.62), 'group_18': np.float64(89.87), 'old': np.float64(85.61), 'new': np.float64(90.29), 'top1': np.float64(86.18), 'top5': np.float64(96.18), 'grouped': {'total': np.float64(86.18), 'group_1': np.float64(91.12), 'group_2': np.float64(84.62), 'group_3': np.float64(83.82), 'group_4': np.float64(84.36), 'group_5': np.float64(86.63), 'group_6': np.float64(84.67), 'group_7': np.float64(85.91), 'group_8': np.float64(84.66), 'group_9': np.float64(93.13), 'group_10': np.float64(84.87), 'group_11': np.float64(85.71), 'group_12': np.float64(88.55), 'group_13': np.float64(85.98), 'group_14': np.float64(73.57), 'group_15': np.float64(83.09), 'group_16': np.float64(89.21), 'group_17': np.float64(90.62), 'group_18': np.float64(89.87), 'old': np.float64(85.61), 'new': np.float64(90.29), 'top1': np.float64(86.18), 'top5': np.float64(96.18)}}
2026-01-16 07:08:50,639 [trainer.py] => No NME accuracy.
2026-01-16 07:08:50,640 [trainer.py] => CNN: {'total': np.float64(86.18), 'group_1': np.float64(91.12), 'group_2': np.float64(84.62), 'group_3': np.float64(83.82), 'group_4': np.float64(84.36), 'group_5': np.float64(86.63), 'group_6': np.float64(84.67), 'group_7': np.float64(85.91), 'group_8': np.float64(84.66), 'group_9': np.float64(93.13), 'group_10': np.float64(84.87), 'group_11': np.float64(85.71), 'group_12': np.float64(88.55), 'group_13': np.float64(85.98), 'group_14': np.float64(73.57), 'group_15': np.float64(83.09), 'group_16': np.float64(89.21), 'group_17': np.float64(90.62), 'group_18': np.float64(89.87), 'old': np.float64(85.61), 'new': np.float64(90.29), 'top1': np.float64(86.18), 'top5': np.float64(96.18)}
2026-01-16 07:08:50,643 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56), np.float64(86.18)]
2026-01-16 07:08:50,649 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56), np.float64(96.18)]

2026-01-16 07:08:50,657 [trainer.py] => Average Accuracy (CNN): 90.62555555555556
2026-01-16 07:08:50,658 [SGC.py] => Learning on task 9 (10 new classes): 90-99
2026-01-16 07:08:50,660 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 07:09:35,771 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 07:09:58,819 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 07:09:58,819 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 07:09:58,822 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87], 19: [90, 92, 95, 96, 97], 20: [91, 93, 94, 98, 99]}
2026-01-16 07:09:58,855 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 07:10:22,548 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 07:10:22,843 [SGC.py] => Starting model training. Training ALL 20 groups.
2026-01-16 07:10:22,845 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]
2026-01-16 07:11:31,986 [SGC.py] => Task: 9, Epoch: 1, Train Loss: 0.730085, Train Acc: 88.5186, Test Acc on New: 1.0471
2026-01-16 07:11:32,041 [SGC.py] => New best accuracy found: 1.05%
2026-01-16 07:16:30,364 [SGC.py] => Task: 9, Epoch: 11, Train Loss: 0.087492, Train Acc: 99.5145, Test Acc on New: 79.0576
2026-01-16 07:16:30,412 [SGC.py] => New best accuracy found: 79.06%
2026-01-16 07:21:29,951 [SGC.py] => Task: 9, Epoch: 21, Train Loss: 0.063025, Train Acc: 99.8557, Test Acc on New: 82.1990
2026-01-16 07:21:30,000 [SGC.py] => New best accuracy found: 82.20%
2026-01-16 07:26:30,352 [SGC.py] => Task: 9, Epoch: 31, Train Loss: 0.054222, Train Acc: 99.9081, Test Acc on New: 79.5812
2026-01-16 07:26:30,353 [SGC.py] => Loading best model for task 9 with Test Acc on New: 82.20%
2026-01-16 07:27:22,402 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 07:27:22,404 [SGC.py] => CNN accuracy: {'total': np.float64(84.21), 'group_1': np.float64(86.39), 'group_2': np.float64(84.62), 'group_3': np.float64(83.82), 'group_4': np.float64(86.59), 'group_5': np.float64(86.63), 'group_6': np.float64(79.56), 'group_7': np.float64(87.25), 'group_8': np.float64(86.24), 'group_9': np.float64(92.37), 'group_10': np.float64(75.66), 'group_11': np.float64(85.71), 'group_12': np.float64(85.54), 'group_13': np.float64(84.76), 'group_14': np.float64(74.29), 'group_15': np.float64(78.68), 'group_16': np.float64(87.77), 'group_17': np.float64(85.42), 'group_18': np.float64(84.81), 'group_19': np.float64(83.52), 'group_20': np.float64(81.0), 'old': np.float64(84.34), 'new': np.float64(82.2), 'top1': np.float64(84.21), 'top5': np.float64(95.41), 'grouped': {'total': np.float64(84.21), 'group_1': np.float64(86.39), 'group_2': np.float64(84.62), 'group_3': np.float64(83.82), 'group_4': np.float64(86.59), 'group_5': np.float64(86.63), 'group_6': np.float64(79.56), 'group_7': np.float64(87.25), 'group_8': np.float64(86.24), 'group_9': np.float64(92.37), 'group_10': np.float64(75.66), 'group_11': np.float64(85.71), 'group_12': np.float64(85.54), 'group_13': np.float64(84.76), 'group_14': np.float64(74.29), 'group_15': np.float64(78.68), 'group_16': np.float64(87.77), 'group_17': np.float64(85.42), 'group_18': np.float64(84.81), 'group_19': np.float64(83.52), 'group_20': np.float64(81.0), 'old': np.float64(84.34), 'new': np.float64(82.2), 'top1': np.float64(84.21), 'top5': np.float64(95.41)}}
2026-01-16 07:27:22,408 [trainer.py] => No NME accuracy.
2026-01-16 07:27:22,416 [trainer.py] => CNN: {'total': np.float64(84.21), 'group_1': np.float64(86.39), 'group_2': np.float64(84.62), 'group_3': np.float64(83.82), 'group_4': np.float64(86.59), 'group_5': np.float64(86.63), 'group_6': np.float64(79.56), 'group_7': np.float64(87.25), 'group_8': np.float64(86.24), 'group_9': np.float64(92.37), 'group_10': np.float64(75.66), 'group_11': np.float64(85.71), 'group_12': np.float64(85.54), 'group_13': np.float64(84.76), 'group_14': np.float64(74.29), 'group_15': np.float64(78.68), 'group_16': np.float64(87.77), 'group_17': np.float64(85.42), 'group_18': np.float64(84.81), 'group_19': np.float64(83.52), 'group_20': np.float64(81.0), 'old': np.float64(84.34), 'new': np.float64(82.2), 'top1': np.float64(84.21), 'top5': np.float64(95.41)}
2026-01-16 07:27:22,426 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56), np.float64(86.18), np.float64(84.21)]
2026-01-16 07:27:22,429 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56), np.float64(96.18), np.float64(95.41)]

2026-01-16 07:27:22,429 [trainer.py] => Average Accuracy (CNN): 89.98400000000001
2026-01-16 07:27:22,429 [SGC.py] => Learning on task 10 (10 new classes): 100-109
2026-01-16 07:27:22,431 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 07:28:09,199 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 07:28:33,840 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 07:28:33,840 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 07:28:33,843 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87], 19: [90, 92, 95, 96, 97], 20: [91, 93, 94, 98, 99], 21: [100, 101, 102, 103, 105], 22: [104, 106, 107, 108, 109]}
2026-01-16 07:28:33,870 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 07:28:58,806 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 07:28:59,161 [SGC.py] => Starting model training. Training ALL 22 groups.
2026-01-16 07:28:59,164 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22]
2026-01-16 07:30:19,005 [SGC.py] => Task: 10, Epoch: 1, Train Loss: 0.558855, Train Acc: 89.4519, Test Acc on New: 39.6610
2026-01-16 07:30:19,070 [SGC.py] => New best accuracy found: 39.66%
2026-01-16 07:37:02,225 [SGC.py] => Task: 10, Epoch: 11, Train Loss: 0.078123, Train Acc: 99.6857, Test Acc on New: 87.4576
2026-01-16 07:37:02,284 [SGC.py] => New best accuracy found: 87.46%
2026-01-16 10:21:11,450 [SGC.py] => Task: 10, Epoch: 21, Train Loss: 0.060461, Train Acc: 99.9157, Test Acc on New: 88.4746
2026-01-16 10:21:11,481 [SGC.py] => New best accuracy found: 88.47%
2026-01-16 10:27:58,263 [SGC.py] => Task: 10, Epoch: 31, Train Loss: 0.052629, Train Acc: 99.9003, Test Acc on New: 87.7966
2026-01-16 10:27:58,263 [SGC.py] => Loading best model for task 10 with Test Acc on New: 88.47%
2026-01-16 10:28:53,286 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 10:28:53,288 [SGC.py] => CNN accuracy: {'total': np.float64(84.19), 'group_1': np.float64(88.17), 'group_2': np.float64(79.49), 'group_3': np.float64(85.78), 'group_4': np.float64(83.8), 'group_5': np.float64(86.05), 'group_6': np.float64(81.02), 'group_7': np.float64(85.91), 'group_8': np.float64(86.77), 'group_9': np.float64(92.37), 'group_10': np.float64(76.32), 'group_11': np.float64(88.44), 'group_12': np.float64(87.35), 'group_13': np.float64(86.59), 'group_14': np.float64(77.86), 'group_15': np.float64(82.35), 'group_16': np.float64(83.45), 'group_17': np.float64(83.85), 'group_18': np.float64(81.65), 'group_19': np.float64(74.73), 'group_20': np.float64(75.0), 'group_21': np.float64(85.82), 'group_22': np.float64(90.91), 'old': np.float64(83.78), 'new': np.float64(88.47), 'top1': np.float64(84.19), 'top5': np.float64(95.51), 'grouped': {'total': np.float64(84.19), 'group_1': np.float64(88.17), 'group_2': np.float64(79.49), 'group_3': np.float64(85.78), 'group_4': np.float64(83.8), 'group_5': np.float64(86.05), 'group_6': np.float64(81.02), 'group_7': np.float64(85.91), 'group_8': np.float64(86.77), 'group_9': np.float64(92.37), 'group_10': np.float64(76.32), 'group_11': np.float64(88.44), 'group_12': np.float64(87.35), 'group_13': np.float64(86.59), 'group_14': np.float64(77.86), 'group_15': np.float64(82.35), 'group_16': np.float64(83.45), 'group_17': np.float64(83.85), 'group_18': np.float64(81.65), 'group_19': np.float64(74.73), 'group_20': np.float64(75.0), 'group_21': np.float64(85.82), 'group_22': np.float64(90.91), 'old': np.float64(83.78), 'new': np.float64(88.47), 'top1': np.float64(84.19), 'top5': np.float64(95.51)}}
2026-01-16 10:28:53,292 [trainer.py] => No NME accuracy.
2026-01-16 10:28:53,296 [trainer.py] => CNN: {'total': np.float64(84.19), 'group_1': np.float64(88.17), 'group_2': np.float64(79.49), 'group_3': np.float64(85.78), 'group_4': np.float64(83.8), 'group_5': np.float64(86.05), 'group_6': np.float64(81.02), 'group_7': np.float64(85.91), 'group_8': np.float64(86.77), 'group_9': np.float64(92.37), 'group_10': np.float64(76.32), 'group_11': np.float64(88.44), 'group_12': np.float64(87.35), 'group_13': np.float64(86.59), 'group_14': np.float64(77.86), 'group_15': np.float64(82.35), 'group_16': np.float64(83.45), 'group_17': np.float64(83.85), 'group_18': np.float64(81.65), 'group_19': np.float64(74.73), 'group_20': np.float64(75.0), 'group_21': np.float64(85.82), 'group_22': np.float64(90.91), 'old': np.float64(83.78), 'new': np.float64(88.47), 'top1': np.float64(84.19), 'top5': np.float64(95.51)}
2026-01-16 10:28:53,304 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56), np.float64(86.18), np.float64(84.21), np.float64(84.19)]
2026-01-16 10:28:53,306 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56), np.float64(96.18), np.float64(95.41), np.float64(95.51)]

2026-01-16 10:28:53,307 [trainer.py] => Average Accuracy (CNN): 89.45727272727275
2026-01-16 10:28:53,307 [SGC.py] => Learning on task 11 (10 new classes): 110-119
2026-01-16 10:28:53,309 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 10:29:45,647 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 10:30:11,754 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 10:30:11,755 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 10:30:11,757 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87], 19: [90, 92, 95, 96, 97], 20: [91, 93, 94, 98, 99], 21: [100, 101, 102, 103, 105], 22: [104, 106, 107, 108, 109], 23: [110, 111, 112, 114, 119], 24: [113, 115, 116, 117, 118]}
2026-01-16 10:30:11,794 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 10:30:37,882 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 10:30:38,214 [SGC.py] => Starting model training. Training ALL 24 groups.
2026-01-16 10:30:38,217 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24]
2026-01-16 10:32:11,161 [SGC.py] => Task: 11, Epoch: 1, Train Loss: 0.490541, Train Acc: 91.5070, Test Acc on New: 54.9072
2026-01-16 10:32:11,221 [SGC.py] => New best accuracy found: 54.91%
2026-01-16 10:40:50,013 [SGC.py] => Task: 11, Epoch: 11, Train Loss: 0.072151, Train Acc: 99.8643, Test Acc on New: 87.7984
2026-01-16 10:40:50,037 [SGC.py] => New best accuracy found: 87.80%
2026-01-16 10:48:04,625 [SGC.py] => Task: 11, Epoch: 21, Train Loss: 0.057744, Train Acc: 99.9023, Test Acc on New: 87.5332
2026-01-16 10:55:40,420 [SGC.py] => Task: 11, Epoch: 31, Train Loss: 0.049697, Train Acc: 99.9240, Test Acc on New: 88.3289
2026-01-16 10:55:40,483 [SGC.py] => New best accuracy found: 88.33%
2026-01-16 10:55:40,483 [SGC.py] => Loading best model for task 11 with Test Acc on New: 88.33%
2026-01-16 10:56:34,074 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 10:56:34,077 [SGC.py] => CNN accuracy: {'total': np.float64(83.81), 'group_1': np.float64(89.94), 'group_2': np.float64(82.05), 'group_3': np.float64(85.29), 'group_4': np.float64(81.01), 'group_5': np.float64(85.47), 'group_6': np.float64(81.75), 'group_7': np.float64(83.89), 'group_8': np.float64(85.19), 'group_9': np.float64(91.6), 'group_10': np.float64(74.34), 'group_11': np.float64(82.31), 'group_12': np.float64(87.35), 'group_13': np.float64(87.2), 'group_14': np.float64(72.14), 'group_15': np.float64(77.94), 'group_16': np.float64(85.61), 'group_17': np.float64(84.9), 'group_18': np.float64(83.54), 'group_19': np.float64(74.73), 'group_20': np.float64(77.0), 'group_21': np.float64(82.98), 'group_22': np.float64(87.66), 'group_23': np.float64(86.89), 'group_24': np.float64(89.69), 'old': np.float64(83.3), 'new': np.float64(88.33), 'top1': np.float64(83.81), 'top5': np.float64(95.48), 'grouped': {'total': np.float64(83.81), 'group_1': np.float64(89.94), 'group_2': np.float64(82.05), 'group_3': np.float64(85.29), 'group_4': np.float64(81.01), 'group_5': np.float64(85.47), 'group_6': np.float64(81.75), 'group_7': np.float64(83.89), 'group_8': np.float64(85.19), 'group_9': np.float64(91.6), 'group_10': np.float64(74.34), 'group_11': np.float64(82.31), 'group_12': np.float64(87.35), 'group_13': np.float64(87.2), 'group_14': np.float64(72.14), 'group_15': np.float64(77.94), 'group_16': np.float64(85.61), 'group_17': np.float64(84.9), 'group_18': np.float64(83.54), 'group_19': np.float64(74.73), 'group_20': np.float64(77.0), 'group_21': np.float64(82.98), 'group_22': np.float64(87.66), 'group_23': np.float64(86.89), 'group_24': np.float64(89.69), 'old': np.float64(83.3), 'new': np.float64(88.33), 'top1': np.float64(83.81), 'top5': np.float64(95.48)}}
2026-01-16 10:56:34,083 [trainer.py] => No NME accuracy.
2026-01-16 10:56:34,091 [trainer.py] => CNN: {'total': np.float64(83.81), 'group_1': np.float64(89.94), 'group_2': np.float64(82.05), 'group_3': np.float64(85.29), 'group_4': np.float64(81.01), 'group_5': np.float64(85.47), 'group_6': np.float64(81.75), 'group_7': np.float64(83.89), 'group_8': np.float64(85.19), 'group_9': np.float64(91.6), 'group_10': np.float64(74.34), 'group_11': np.float64(82.31), 'group_12': np.float64(87.35), 'group_13': np.float64(87.2), 'group_14': np.float64(72.14), 'group_15': np.float64(77.94), 'group_16': np.float64(85.61), 'group_17': np.float64(84.9), 'group_18': np.float64(83.54), 'group_19': np.float64(74.73), 'group_20': np.float64(77.0), 'group_21': np.float64(82.98), 'group_22': np.float64(87.66), 'group_23': np.float64(86.89), 'group_24': np.float64(89.69), 'old': np.float64(83.3), 'new': np.float64(88.33), 'top1': np.float64(83.81), 'top5': np.float64(95.48)}
2026-01-16 10:56:34,095 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56), np.float64(86.18), np.float64(84.21), np.float64(84.19), np.float64(83.81)]
2026-01-16 10:56:34,095 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56), np.float64(96.18), np.float64(95.41), np.float64(95.51), np.float64(95.48)]

2026-01-16 10:56:34,095 [trainer.py] => Average Accuracy (CNN): 88.98666666666668
2026-01-16 10:56:34,095 [SGC.py] => Learning on task 12 (10 new classes): 120-129
2026-01-16 10:56:34,099 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 10:57:21,092 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 10:57:44,131 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 10:57:44,131 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 10:57:44,132 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87], 19: [90, 92, 95, 96, 97], 20: [91, 93, 94, 98, 99], 21: [100, 101, 102, 103, 105], 22: [104, 106, 107, 108, 109], 23: [110, 111, 112, 114, 119], 24: [113, 115, 116, 117, 118], 25: [120, 121, 122, 125, 126], 26: [123, 124, 127, 128, 129]}
2026-01-16 10:57:44,156 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 10:57:59,070 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 10:57:59,316 [SGC.py] => Starting model training. Training ALL 26 groups.
2026-01-16 10:57:59,325 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26]
2026-01-16 10:59:13,724 [SGC.py] => Task: 12, Epoch: 1, Train Loss: 0.561130, Train Acc: 90.6945, Test Acc on New: 28.9683
2026-01-16 10:59:13,781 [SGC.py] => New best accuracy found: 28.97%
2026-01-16 11:05:39,252 [SGC.py] => Task: 12, Epoch: 11, Train Loss: 0.072704, Train Acc: 99.7411, Test Acc on New: 86.1111
2026-01-16 11:05:39,273 [SGC.py] => New best accuracy found: 86.11%
2026-01-16 11:12:52,499 [SGC.py] => Task: 12, Epoch: 21, Train Loss: 0.057183, Train Acc: 99.8858, Test Acc on New: 89.2857
2026-01-16 11:12:52,576 [SGC.py] => New best accuracy found: 89.29%
2026-01-16 11:19:39,738 [SGC.py] => Task: 12, Epoch: 31, Train Loss: 0.049827, Train Acc: 99.9086, Test Acc on New: 88.0952
2026-01-16 11:19:39,738 [SGC.py] => Loading best model for task 12 with Test Acc on New: 89.29%
2026-01-16 11:20:34,272 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 11:20:34,277 [SGC.py] => CNN accuracy: {'total': np.float64(83.43), 'group_1': np.float64(89.35), 'group_2': np.float64(82.05), 'group_3': np.float64(79.9), 'group_4': np.float64(82.12), 'group_5': np.float64(86.63), 'group_6': np.float64(74.45), 'group_7': np.float64(84.56), 'group_8': np.float64(87.3), 'group_9': np.float64(88.55), 'group_10': np.float64(75.0), 'group_11': np.float64(82.31), 'group_12': np.float64(88.55), 'group_13': np.float64(84.76), 'group_14': np.float64(73.57), 'group_15': np.float64(80.15), 'group_16': np.float64(84.89), 'group_17': np.float64(82.29), 'group_18': np.float64(84.18), 'group_19': np.float64(71.43), 'group_20': np.float64(79.0), 'group_21': np.float64(83.69), 'group_22': np.float64(88.31), 'group_23': np.float64(86.34), 'group_24': np.float64(84.02), 'group_25': np.float64(92.42), 'group_26': np.float64(85.83), 'old': np.float64(83.03), 'new': np.float64(89.29), 'top1': np.float64(83.43), 'top5': np.float64(94.84), 'grouped': {'total': np.float64(83.43), 'group_1': np.float64(89.35), 'group_2': np.float64(82.05), 'group_3': np.float64(79.9), 'group_4': np.float64(82.12), 'group_5': np.float64(86.63), 'group_6': np.float64(74.45), 'group_7': np.float64(84.56), 'group_8': np.float64(87.3), 'group_9': np.float64(88.55), 'group_10': np.float64(75.0), 'group_11': np.float64(82.31), 'group_12': np.float64(88.55), 'group_13': np.float64(84.76), 'group_14': np.float64(73.57), 'group_15': np.float64(80.15), 'group_16': np.float64(84.89), 'group_17': np.float64(82.29), 'group_18': np.float64(84.18), 'group_19': np.float64(71.43), 'group_20': np.float64(79.0), 'group_21': np.float64(83.69), 'group_22': np.float64(88.31), 'group_23': np.float64(86.34), 'group_24': np.float64(84.02), 'group_25': np.float64(92.42), 'group_26': np.float64(85.83), 'old': np.float64(83.03), 'new': np.float64(89.29), 'top1': np.float64(83.43), 'top5': np.float64(94.84)}}
2026-01-16 11:20:34,277 [trainer.py] => No NME accuracy.
2026-01-16 11:20:34,278 [trainer.py] => CNN: {'total': np.float64(83.43), 'group_1': np.float64(89.35), 'group_2': np.float64(82.05), 'group_3': np.float64(79.9), 'group_4': np.float64(82.12), 'group_5': np.float64(86.63), 'group_6': np.float64(74.45), 'group_7': np.float64(84.56), 'group_8': np.float64(87.3), 'group_9': np.float64(88.55), 'group_10': np.float64(75.0), 'group_11': np.float64(82.31), 'group_12': np.float64(88.55), 'group_13': np.float64(84.76), 'group_14': np.float64(73.57), 'group_15': np.float64(80.15), 'group_16': np.float64(84.89), 'group_17': np.float64(82.29), 'group_18': np.float64(84.18), 'group_19': np.float64(71.43), 'group_20': np.float64(79.0), 'group_21': np.float64(83.69), 'group_22': np.float64(88.31), 'group_23': np.float64(86.34), 'group_24': np.float64(84.02), 'group_25': np.float64(92.42), 'group_26': np.float64(85.83), 'old': np.float64(83.03), 'new': np.float64(89.29), 'top1': np.float64(83.43), 'top5': np.float64(94.84)}
2026-01-16 11:20:34,278 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56), np.float64(86.18), np.float64(84.21), np.float64(84.19), np.float64(83.81), np.float64(83.43)]
2026-01-16 11:20:34,278 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56), np.float64(96.18), np.float64(95.41), np.float64(95.51), np.float64(95.48), np.float64(94.84)]

2026-01-16 11:20:34,278 [trainer.py] => Average Accuracy (CNN): 88.55923076923078
2026-01-16 11:20:34,278 [SGC.py] => Learning on task 13 (10 new classes): 130-139
2026-01-16 11:20:34,281 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 11:21:23,496 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 11:21:48,953 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 11:21:48,954 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 11:21:48,956 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87], 19: [90, 92, 95, 96, 97], 20: [91, 93, 94, 98, 99], 21: [100, 101, 102, 103, 105], 22: [104, 106, 107, 108, 109], 23: [110, 111, 112, 114, 119], 24: [113, 115, 116, 117, 118], 25: [120, 121, 122, 125, 126], 26: [123, 124, 127, 128, 129], 27: [130, 131, 134, 137, 138], 28: [132, 133, 135, 136, 139]}
2026-01-16 11:21:48,977 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 11:22:16,393 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 11:22:16,859 [SGC.py] => Starting model training. Training ALL 28 groups.
2026-01-16 11:22:16,861 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28]
2026-01-16 11:23:58,048 [SGC.py] => Task: 13, Epoch: 1, Train Loss: 0.470506, Train Acc: 91.7615, Test Acc on New: 50.0000
2026-01-16 11:23:58,096 [SGC.py] => New best accuracy found: 50.00%
2026-01-16 11:33:03,945 [SGC.py] => Task: 13, Epoch: 11, Train Loss: 0.074552, Train Acc: 99.7410, Test Acc on New: 86.8243
2026-01-16 11:33:03,989 [SGC.py] => New best accuracy found: 86.82%
2026-01-16 11:41:01,430 [SGC.py] => Task: 13, Epoch: 21, Train Loss: 0.057799, Train Acc: 99.8916, Test Acc on New: 87.8378
2026-01-16 11:41:01,484 [SGC.py] => New best accuracy found: 87.84%
2026-01-16 11:49:44,212 [SGC.py] => Task: 13, Epoch: 31, Train Loss: 0.050920, Train Acc: 99.8796, Test Acc on New: 87.8378
2026-01-16 11:49:44,212 [SGC.py] => Loading best model for task 13 with Test Acc on New: 87.84%
2026-01-16 11:50:55,162 [toolkit.py] => Calculating accuracy per defined class group.
2026-01-16 11:50:55,166 [SGC.py] => CNN accuracy: {'total': np.float64(82.75), 'group_1': np.float64(87.57), 'group_2': np.float64(81.41), 'group_3': np.float64(80.39), 'group_4': np.float64(82.68), 'group_5': np.float64(85.47), 'group_6': np.float64(79.56), 'group_7': np.float64(82.55), 'group_8': np.float64(85.71), 'group_9': np.float64(87.02), 'group_10': np.float64(79.61), 'group_11': np.float64(80.27), 'group_12': np.float64(84.94), 'group_13': np.float64(81.71), 'group_14': np.float64(73.57), 'group_15': np.float64(79.41), 'group_16': np.float64(84.89), 'group_17': np.float64(83.33), 'group_18': np.float64(84.18), 'group_19': np.float64(69.23), 'group_20': np.float64(78.0), 'group_21': np.float64(85.82), 'group_22': np.float64(83.77), 'group_23': np.float64(84.7), 'group_24': np.float64(82.47), 'group_25': np.float64(88.64), 'group_26': np.float64(75.0), 'group_27': np.float64(90.66), 'group_28': np.float64(83.33), 'old': np.float64(82.38), 'new': np.float64(87.84), 'top1': np.float64(82.75), 'top5': np.float64(94.8), 'grouped': {'total': np.float64(82.75), 'group_1': np.float64(87.57), 'group_2': np.float64(81.41), 'group_3': np.float64(80.39), 'group_4': np.float64(82.68), 'group_5': np.float64(85.47), 'group_6': np.float64(79.56), 'group_7': np.float64(82.55), 'group_8': np.float64(85.71), 'group_9': np.float64(87.02), 'group_10': np.float64(79.61), 'group_11': np.float64(80.27), 'group_12': np.float64(84.94), 'group_13': np.float64(81.71), 'group_14': np.float64(73.57), 'group_15': np.float64(79.41), 'group_16': np.float64(84.89), 'group_17': np.float64(83.33), 'group_18': np.float64(84.18), 'group_19': np.float64(69.23), 'group_20': np.float64(78.0), 'group_21': np.float64(85.82), 'group_22': np.float64(83.77), 'group_23': np.float64(84.7), 'group_24': np.float64(82.47), 'group_25': np.float64(88.64), 'group_26': np.float64(75.0), 'group_27': np.float64(90.66), 'group_28': np.float64(83.33), 'old': np.float64(82.38), 'new': np.float64(87.84), 'top1': np.float64(82.75), 'top5': np.float64(94.8)}}
2026-01-16 11:50:55,166 [trainer.py] => No NME accuracy.
2026-01-16 11:50:55,166 [trainer.py] => CNN: {'total': np.float64(82.75), 'group_1': np.float64(87.57), 'group_2': np.float64(81.41), 'group_3': np.float64(80.39), 'group_4': np.float64(82.68), 'group_5': np.float64(85.47), 'group_6': np.float64(79.56), 'group_7': np.float64(82.55), 'group_8': np.float64(85.71), 'group_9': np.float64(87.02), 'group_10': np.float64(79.61), 'group_11': np.float64(80.27), 'group_12': np.float64(84.94), 'group_13': np.float64(81.71), 'group_14': np.float64(73.57), 'group_15': np.float64(79.41), 'group_16': np.float64(84.89), 'group_17': np.float64(83.33), 'group_18': np.float64(84.18), 'group_19': np.float64(69.23), 'group_20': np.float64(78.0), 'group_21': np.float64(85.82), 'group_22': np.float64(83.77), 'group_23': np.float64(84.7), 'group_24': np.float64(82.47), 'group_25': np.float64(88.64), 'group_26': np.float64(75.0), 'group_27': np.float64(90.66), 'group_28': np.float64(83.33), 'old': np.float64(82.38), 'new': np.float64(87.84), 'top1': np.float64(82.75), 'top5': np.float64(94.8)}
2026-01-16 11:50:55,167 [trainer.py] => CNN top1 curve: [np.float64(96.0), np.float64(95.34), np.float64(92.53), np.float64(91.29), np.float64(90.54), np.float64(89.65), np.float64(87.54), np.float64(86.56), np.float64(86.18), np.float64(84.21), np.float64(84.19), np.float64(83.81), np.float64(83.43), np.float64(82.75)]
2026-01-16 11:50:55,169 [trainer.py] => CNN top5 curve: [np.float64(99.38), np.float64(99.01), np.float64(98.03), np.float64(97.71), np.float64(97.44), np.float64(97.33), np.float64(96.36), np.float64(96.56), np.float64(96.18), np.float64(95.41), np.float64(95.51), np.float64(95.48), np.float64(94.84), np.float64(94.8)]

2026-01-16 11:50:55,175 [trainer.py] => Average Accuracy (CNN): 88.14428571428573
2026-01-16 11:50:55,175 [SGC.py] => Learning on task 14 (10 new classes): 140-149
2026-01-16 11:50:55,178 [SGC.py] => Building prototypes and covariance for new classes...
2026-01-16 11:51:54,690 [SGC.py] => Part 1: Grouping new classes...
2026-01-16 11:52:25,033 [SGC.py] => Task has 10 classes. Using standard grouping strategy.
2026-01-16 11:52:25,034 [SGC.py] => Task size is even. Splitting into two groups via Max-Cut.
2026-01-16 11:52:25,036 [SGC.py] => Grouping complete. Current p2c map: {1: [0, 2, 3, 5, 6], 2: [1, 4, 7, 8, 9], 3: [10, 11, 12, 17, 19], 4: [13, 14, 15, 16, 18], 5: [20, 21, 23, 28, 29], 6: [22, 24, 25, 26, 27], 7: [30, 31, 33, 34, 36], 8: [32, 35, 37, 38, 39], 9: [40, 41, 43, 44, 48], 10: [42, 45, 46, 47, 49], 11: [50, 51, 53, 54, 58], 12: [52, 55, 56, 57, 59], 13: [60, 61, 63, 64, 69], 14: [62, 65, 66, 67, 68], 15: [70, 71, 74, 76, 79], 16: [72, 73, 75, 77, 78], 17: [80, 81, 83, 88, 89], 18: [82, 84, 85, 86, 87], 19: [90, 92, 95, 96, 97], 20: [91, 93, 94, 98, 99], 21: [100, 101, 102, 103, 105], 22: [104, 106, 107, 108, 109], 23: [110, 111, 112, 114, 119], 24: [113, 115, 116, 117, 118], 25: [120, 121, 122, 125, 126], 26: [123, 124, 127, 128, 129], 27: [130, 131, 134, 137, 138], 28: [132, 133, 135, 136, 139], 29: [140, 142, 143, 144, 149], 30: [141, 145, 146, 147, 148]}
2026-01-16 11:52:25,061 [SGC.py] => Building feature set using Balanced Strategy (Interpolation + Gaussian)...
2026-01-16 11:52:52,137 [SGC.py] => Generating pseudo-features for old classes via mixing...
2026-01-16 11:52:52,591 [SGC.py] => Starting model training. Training ALL 30 groups.
2026-01-16 11:52:52,594 [SGC.py] => Unfreezing components for ALL groups: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2026-01-16 11:54:29,960 [SGC.py] => Task: 14, Epoch: 1, Train Loss: 0.460701, Train Acc: 92.1468, Test Acc on New: 48.4765
2026-01-16 11:54:30,004 [SGC.py] => New best accuracy found: 48.48%
2026-01-16 12:06:37,345 [SGC.py] => Task: 14, Epoch: 11, Train Loss: 0.068653, Train Acc: 99.8268, Test Acc on New: 89.1967
2026-01-16 12:06:37,427 [SGC.py] => New best accuracy found: 89.20%
